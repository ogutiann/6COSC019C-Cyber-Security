{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSQpHMegJmhzMqQEbUx+lm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5049b8ef8a04435994ad344e31527292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0eba697a64144f3e8b6fde3e77b97cc4",
              "IPY_MODEL_0660063e2b3b4e58b7ef40148b7024bd",
              "IPY_MODEL_7f5535c2583f459fbe968238a668d82d"
            ],
            "layout": "IPY_MODEL_55246e70760c45dabf936981730119bf"
          }
        },
        "0eba697a64144f3e8b6fde3e77b97cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b117c5c97408413e8b49f9a24a508e3d",
            "placeholder": "​",
            "style": "IPY_MODEL_a7dcaf7709dd4d71bde9729d4d0af2e5",
            "value": "Computing widget examples:   0%"
          }
        },
        "0660063e2b3b4e58b7ef40148b7024bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f41d6ffc35c4abb9ca45dadd27b935d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d073a4a478e40ae85e6c1d8cd4ae381",
            "value": 1
          }
        },
        "7f5535c2583f459fbe968238a668d82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cbe72fe416240bfaeac315309e26b83",
            "placeholder": "​",
            "style": "IPY_MODEL_55d130fa4f1b487cac8e977f8d8e70ff",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "55246e70760c45dabf936981730119bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b117c5c97408413e8b49f9a24a508e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7dcaf7709dd4d71bde9729d4d0af2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f41d6ffc35c4abb9ca45dadd27b935d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d073a4a478e40ae85e6c1d8cd4ae381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cbe72fe416240bfaeac315309e26b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d130fa4f1b487cac8e977f8d8e70ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7246e836ecb9487884f38696f9286401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5940b9163cff438b82cead16e2119b4c",
              "IPY_MODEL_e8f3f6eef1f14161866dba37acd10064",
              "IPY_MODEL_18978d11462c484ebf10424523140175"
            ],
            "layout": "IPY_MODEL_7dcd472cee0a4ab9941277c39d8f37a1"
          }
        },
        "5940b9163cff438b82cead16e2119b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6cf9ca1ea0044fe988bdf925ce1ebce",
            "placeholder": "​",
            "style": "IPY_MODEL_a434b511a7994149be846a95b52abc5f",
            "value": "Computing widget examples:   0%"
          }
        },
        "e8f3f6eef1f14161866dba37acd10064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4c1d15269e2496f86ea13222b1c611b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef9567665c29497abc54bc861193bb2a",
            "value": 1
          }
        },
        "18978d11462c484ebf10424523140175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b4492e947c4445b48c94870bbe9037",
            "placeholder": "​",
            "style": "IPY_MODEL_26e6d5b1d60248dba229e6bf98070111",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "7dcd472cee0a4ab9941277c39d8f37a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e6cf9ca1ea0044fe988bdf925ce1ebce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a434b511a7994149be846a95b52abc5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4c1d15269e2496f86ea13222b1c611b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef9567665c29497abc54bc861193bb2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4b4492e947c4445b48c94870bbe9037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e6d5b1d60248dba229e6bf98070111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ogutiann/6COSC019C-Cyber-Security/blob/main/EduPathAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Sankofa Pathways: AI-Blockchain Adaptive Learning System\n",
        "Core Implementation for Soroti University Case Study\n",
        "\"\"\"\n",
        "import sys\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.cluster import DBSCAN, KMeans  # Added for density-based clustering\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score  # Added cluster validation\n",
        "from sentence_transformers import SentenceTransformer, datasets\n",
        "from scipy.stats import laplace\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import hashlib\n",
        "import json\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "import psutil\n",
        "# Add to top imports\n",
        "from sentence_transformers import SentenceTransformer, models, InputExample, losses\n",
        "from torch.utils.data import DataLoader\n",
        "import nltk\n",
        "\n",
        "\n",
        "# Add these to your top-level imports\n",
        "try:\n",
        "    from gensim.corpora import Dictionary\n",
        "    from gensim.models import CoherenceModel\n",
        "    GENSIM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GENSIM_AVAILABLE = False\n",
        "    print(\"Gensim not installed. Topic coherence metrics disabled.\")\n",
        "\n",
        "\n",
        "try:\n",
        "    from umap import UMAP\n",
        "    UMAP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    UMAP_AVAILABLE = False\n",
        "    print(\"UMAP not installed. Using PCA instead.\")\n",
        "    from sklearn.decomposition import PCA\n",
        "\n",
        "# Add to top imports\n",
        "try:\n",
        "    from hdbscan import HDBSCAN\n",
        "    HDBSCAN_AVAILABLE = True\n",
        "except ImportError:\n",
        "    HDBSCAN_AVAILABLE = False\n",
        "    print(\"HDBSCAN not installed. Using KMeans for clustering.\")\n",
        "\n",
        "# =====================\n",
        "# 0. CONFIGURATION\n",
        "# =====================\n",
        "PRODUCTION_MODE = False # if PRODUCTION_MODE = True  # This prevents model evaluation, set to false and reproducibility mode to true to enable evaluation\n",
        "REPRODUCIBILITY_MODE = True\n",
        "FINE_TUNE_BERT = True  # Global flag to enable/disable fine-tuning\n",
        "IN_COLAB = 'google.colab' in sys.modules  # Detect Colab environment\n",
        "\n",
        "if REPRODUCIBILITY_MODE:\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "    os.environ['PYTHONHASHSEED'] = '42'\n",
        "\n",
        "# Fixed dataset filename\n",
        "DATASET_FILENAME = \"soroti_engineering_dataset.csv\"\n",
        "TEMPLATES_FILENAME = \"assessment_templates.csv\"\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# =====================\n",
        "# 1. DATA PREPROCESSING\n",
        "# =====================\n",
        "\n",
        "class DataPreprocessor:\n",
        "    \"\"\"\n",
        "    Handles data ingestion, anonymization, and normalization\n",
        "    Implements ε-differential privacy (ε=0.85) per Uganda's Data Protection Act\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, epsilon=0.85):\n",
        "        self.epsilon = epsilon\n",
        "        self.imputer = SimpleImputer(strategy='median')\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def validate_data(self, df):\n",
        "        \"\"\"Ensure data quality before processing\"\"\"\n",
        "        if df.isnull().sum().sum() > 0:\n",
        "            print(f\"Warning: Found {df.isnull().sum().sum()} missing values. Imputing...\")\n",
        "            df = self.imputer.fit_transform(df)\n",
        "        return df\n",
        "\n",
        "    def anonymize_ids(self, student_ids):\n",
        "        \"\"\"Apply SHA-256 hashing to student identifiers\"\"\"\n",
        "        return [hashlib.sha256(str(id).encode()).hexdigest() for id in student_ids]\n",
        "\n",
        "    def add_laplace_noise(self, scores, sensitivity=12):\n",
        "        \"\"\"Inject Laplace noise for differential privacy with reproducibility option\"\"\"\n",
        "        scale = sensitivity / self.epsilon\n",
        "\n",
        "        if REPRODUCIBILITY_MODE:\n",
        "            rng = np.random.default_rng(42)\n",
        "            noise = rng.laplace(scale=scale, size=len(scores))\n",
        "        else:\n",
        "            noise = np.random.laplace(scale=scale, size=len(scores))\n",
        "\n",
        "        return scores + noise\n",
        "\n",
        "    def normalize_scores(self, scores):\n",
        "        \"\"\"Robust z-score standardization by course\"\"\"\n",
        "        return (scores - np.nanmedian(scores)) / (np.nanstd(scores) + 1e-8)\n",
        "\n",
        "    def preprocess(self, raw_data):\n",
        "        \"\"\"\n",
        "        Full preprocessing pipeline:\n",
        "        1. Create ID mapping before anonymization\n",
        "        2. Anonymize student IDs\n",
        "        3. Add Laplace noise to scores\n",
        "        4. Normalize scores by course\n",
        "        \"\"\"\n",
        "        # Create deep copy to avoid mutation\n",
        "        data = raw_data.copy()\n",
        "\n",
        "        # Create ID mapping BEFORE anonymization\n",
        "        self.id_mapping = {id: hashlib.sha256(str(id).encode()).hexdigest()\n",
        "                           for id in data['student_id'].unique()}\n",
        "\n",
        "        # Anonymization using mapping\n",
        "        data['hashed_id'] = data['student_id'].map(self.id_mapping)\n",
        "\n",
        "        # Differential privacy\n",
        "        for course in data['course'].unique():\n",
        "            mask = data['course'] == course\n",
        "            scores = data.loc[mask, 'score'].values\n",
        "            data.loc[mask, 'score'] = self.add_laplace_noise(scores)\n",
        "\n",
        "        # Normalization\n",
        "        for course in data['course'].unique():\n",
        "            mask = data['course'] == course\n",
        "            scores = data.loc[mask, 'score'].values\n",
        "            data.loc[mask, 'z_score'] = self.normalize_scores(scores)\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "# ========================\n",
        "# 2. HYBRID TOPIC MODELING\n",
        "# ========================\n",
        "\n",
        "class HybridTopicModel:\n",
        "    \"\"\"\n",
        "    Principled integration of contextual embeddings (BERT) and probabilistic modeling (LDA)\n",
        "    using topic alignment and semantic coherence measures\n",
        "    Enhanced hybrid model with fine-tuned alignment\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lambda_weight=0.65, n_topics=5, fine_tune_steps=100):\n",
        "        self.bert_model = self.load_bert_model()\n",
        "        self.lda_model = None\n",
        "        self.vectorizer = None\n",
        "        self.lambda_weight = lambda_weight\n",
        "        self.n_topics = n_topics\n",
        "        self.topic_embeddings = None\n",
        "        self.fine_tune_steps = fine_tune_steps\n",
        "        self.word_embeddings = None\n",
        "\n",
        "    def load_bert_model(self):\n",
        "        \"\"\"Robust model loading with explicit Sentence Transformer\"\"\"\n",
        "        try:\n",
        "            print(\"Loading model: sentence-transformers/all-MiniLM-L6-v2\")\n",
        "            model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading BERT model: {str(e)}. Using dummy embeddings.\")\n",
        "            return self.DummyEmbedder()\n",
        "\n",
        "    class DummyEmbedder:\n",
        "        def __init__(self, dim=384):\n",
        "            self.dim = dim\n",
        "\n",
        "        def encode(self, texts):\n",
        "            if isinstance(texts, str):\n",
        "                return np.random.randn(self.dim)\n",
        "            return [np.random.randn(self.dim) for _ in texts]\n",
        "\n",
        "    def fine_tune_bert(self, documents):\n",
        "        \"\"\"Fine-tune BERT with educational texts using paired examples\"\"\"\n",
        "        if not FINE_TUNE_BERT or not IN_COLAB:\n",
        "            print(\"Fine-tuning disabled or not in Colab. Skipping.\")\n",
        "            return\n",
        "        if isinstance(documents, np.ndarray):\n",
        "            documents = documents.tolist()\n",
        "        if not documents or len(documents) < 1:\n",
        "            print(\"Warning: No documents for fine-tuning BERT. Skipping.\")\n",
        "            return\n",
        "\n",
        "        # Create paired InputExamples (anchor and positive are the same document)\n",
        "        examples = []\n",
        "        for doc in documents:\n",
        "            examples.append(InputExample(texts=[doc, doc], label=1.0))  # Label 1.0 for positive pair\n",
        "        train_dataloader = DataLoader(examples, shuffle=True, batch_size=8)\n",
        "\n",
        "        train_loss = losses.CosineSimilarityLoss(self.bert_model)\n",
        "        self.bert_model.fit(\n",
        "            train_objectives=[(train_dataloader, train_loss)],\n",
        "            epochs=self.fine_tune_steps // len(documents) + 1,\n",
        "            warmup_steps=10,\n",
        "            output_path=\"fine_tuned_bert_model\",\n",
        "            use_amp=False\n",
        "        )\n",
        "\n",
        "    def train_lda(self, documents):\n",
        "        # FIXED: Properly handle NumPy arrays\n",
        "        if documents is None or len(documents) == 0:\n",
        "            print(\"Warning: No documents for LDA training. Using default model.\")\n",
        "            self.lda_model = LatentDirichletAllocation(n_components=self.n_topics, random_state=42)\n",
        "            return\n",
        "\n",
        "        academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section', 'example', 'problem',\n",
        "                               'solution', 'study', 'learn']\n",
        "        self.vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english', ngram_range=(1, 2),\n",
        "                                          max_features=1000)\n",
        "        self.vectorizer.stop_words_ = set(list(self.vectorizer.get_stop_words()) + academic_stop_words)\n",
        "        dtm = self.vectorizer.fit_transform(documents)\n",
        "\n",
        "        if GENSIM_AVAILABLE:\n",
        "            best_coherence = -1\n",
        "            for alpha in [0.1, 0.5, 1.0]:\n",
        "                for eta in [0.01, 0.1]:\n",
        "                    lda = LatentDirichletAllocation(\n",
        "                        n_components=self.n_topics,\n",
        "                        learning_method='online',\n",
        "                        learning_offset=10.,\n",
        "                        random_state=42,\n",
        "                        max_iter=15,\n",
        "                        n_jobs=1,\n",
        "                        doc_topic_prior=alpha,\n",
        "                        topic_word_prior=eta\n",
        "                    )\n",
        "                    lda.fit(dtm)\n",
        "                    # Extract topics manually for CoherenceModel\n",
        "                    feature_names = self.vectorizer.get_feature_names_out()\n",
        "                    topics = [[feature_names[i] for i in topic.argsort()[:-11:-1]] for topic in lda.components_]\n",
        "                    coherence_model = CoherenceModel(\n",
        "                        topics=topics,\n",
        "                        texts=[doc.split() for doc in documents],\n",
        "                        dictionary=Dictionary([doc.split() for doc in documents]),\n",
        "                        coherence='c_v'\n",
        "                    )\n",
        "                    coherence = coherence_model.get_coherence()\n",
        "                    if coherence > best_coherence:\n",
        "                        best_coherence = coherence\n",
        "                        self.lda_model = lda\n",
        "        else:\n",
        "            print(\"Gensim not available. Using default LDA model.\")\n",
        "            self.lda_model = LatentDirichletAllocation(\n",
        "                n_components=self.n_topics,\n",
        "                random_state=42,\n",
        "                max_iter=15,\n",
        "                n_jobs=1\n",
        "            )\n",
        "            self.lda_model.fit(dtm)\n",
        "\n",
        "        # FIXED TOPIC TERM GENERATION\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "        top_indices = self.lda_model.components_.argsort(axis=1)[:, ::-1][:, :10]\n",
        "        self.topic_terms = [feature_names[i] for row in top_indices for i in row]\n",
        "\n",
        "    def compute_topic_embeddings(self, documents):\n",
        "        \"\"\"Enhanced topic embedding calculation with documents parameter\"\"\"\n",
        "        # Get document embeddings\n",
        "        doc_embeddings = self.bert_model.encode(documents)\n",
        "\n",
        "        # Cluster documents using BERT embeddings\n",
        "        kmeans = KMeans(n_clusters=self.n_topics, random_state=42)\n",
        "        doc_clusters = kmeans.fit_predict(doc_embeddings)\n",
        "        cluster_centers = kmeans.cluster_centers_\n",
        "\n",
        "        # Get LDA topic-word distributions\n",
        "        topic_word_dist = self.lda_model.components_ / self.lda_model.components_.sum(axis=1)[:, np.newaxis]\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "\n",
        "        # Create enhanced topic embeddings\n",
        "        self.topic_embeddings = []\n",
        "        for i in range(self.n_topics):\n",
        "            # Get top words for LDA topic\n",
        "            top_word_indices = topic_word_dist[i].argsort()[::-1][:15]\n",
        "            top_words = [feature_names[idx] for idx in top_word_indices]\n",
        "\n",
        "            # Get most representative documents for BERT cluster\n",
        "            cluster_docs = [doc for j, doc in enumerate(documents) if doc_clusters[j] == i]\n",
        "            if cluster_docs:\n",
        "                # Encode cluster documents and average\n",
        "                cluster_embeddings = self.bert_model.encode(cluster_docs)\n",
        "                cluster_avg = np.mean(cluster_embeddings, axis=0)\n",
        "            else:\n",
        "                cluster_avg = cluster_centers[i]\n",
        "\n",
        "            # Encode LDA top words and average\n",
        "            word_embeddings = self.bert_model.encode(top_words)\n",
        "            word_avg = np.mean(word_embeddings, axis=0)\n",
        "\n",
        "            # Combine cluster and word embeddings\n",
        "            combined_embedding = (self.lambda_weight * cluster_avg +\n",
        "                                  (1 - self.lambda_weight) * word_avg)\n",
        "            self.topic_embeddings.append(combined_embedding)\n",
        "\n",
        "        self.topic_embeddings = np.array(self.topic_embeddings)\n",
        "\n",
        "    def get_document_topic_distribution(self, documents):\n",
        "        \"\"\"Improved distribution using semantic similarity\"\"\"\n",
        "        doc_embeddings = self.bert_model.encode(documents)\n",
        "        sim_matrix = cosine_similarity(doc_embeddings, self.topic_embeddings)\n",
        "\n",
        "        # Get LDA distribution\n",
        "        dtm = self.vectorizer.transform(documents)\n",
        "        lda_dist = self.lda_model.transform(dtm)\n",
        "\n",
        "        # Combine distributions\n",
        "        hybrid_dist = (self.lambda_weight * sim_matrix +\n",
        "                       (1 - self.lambda_weight) * lda_dist)\n",
        "\n",
        "        # Softmax normalization\n",
        "        hybrid_dist = np.exp(hybrid_dist) / np.sum(np.exp(hybrid_dist), axis=1, keepdims=True)\n",
        "        return hybrid_dist\n",
        "\n",
        "    def get_dominant_topic(self, documents):\n",
        "        \"\"\"Extract dominant topic\"\"\"\n",
        "        hybrid_dist = self.get_document_topic_distribution(documents)\n",
        "        return np.argmax(hybrid_dist, axis=1)\n",
        "\n",
        "# ========================\n",
        "# 2. Enhanced HYBRID TOPIC MODELING\n",
        "# ========================\n",
        "\n",
        "class EnhancedHybridTopicModel:\n",
        "    \"\"\"Paper-inspired hybrid model with UMAP, per-cluster topics, and optimal transport\"\"\"\n",
        "\n",
        "    def __init__(self, lambda_weight=0.85, n_topics=5, fine_tune_steps=200):\n",
        "        self.bert_model = self.load_bert_model()\n",
        "        self.lda_model = None\n",
        "        self.vectorizer = None\n",
        "        self.lambda_weight = lambda_weight\n",
        "        self.n_topics = n_topics\n",
        "        self.topic_embeddings = None\n",
        "        self.fine_tune_steps = fine_tune_steps\n",
        "        self.cluster_model = None\n",
        "        self.reducer = None\n",
        "        self.global_lda_model = None\n",
        "        self.global_vectorizer = None\n",
        "        self.cluster_lda_models = {}\n",
        "        self.cluster_vectorizers = {}\n",
        "        # Add dynamic topic range\n",
        "        self.min_topics = max(3, n_topics - 2)\n",
        "        self.max_topics = n_topics + 3\n",
        "\n",
        "        # Add coherence optimizer\n",
        "        self.coherence_threshold = 0.6\n",
        "\n",
        "    def load_bert_model(self):\n",
        "        \"\"\"Robust model loading with explicit Sentence Transformer\"\"\"\n",
        "        try:\n",
        "            print(\"Loading model: sentence-transformers/all-MiniLM-L6-v2\")\n",
        "            return SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading BERT model: {str(e)}. Using dummy embeddings.\")\n",
        "            return self.DummyEmbedder()\n",
        "\n",
        "    class DummyEmbedder:\n",
        "        def __init__(self, dim=384):\n",
        "            self.dim = dim\n",
        "\n",
        "        def encode(self, texts):\n",
        "            if isinstance(texts, str):\n",
        "                return np.random.randn(self.dim)\n",
        "            return [np.random.randn(self.dim) for _ in texts]\n",
        "\n",
        "    def fine_tune_bert(self, documents):\n",
        "        \"\"\"Fine-tune BERT with educational texts using paired examples\"\"\"\n",
        "        if not FINE_TUNE_BERT or not IN_COLAB:\n",
        "            print(\"Fine-tuning disabled or not in Colab. Skipping.\")\n",
        "            return\n",
        "        if isinstance(documents, np.ndarray):\n",
        "            documents = documents.tolist()\n",
        "        if not documents or len(documents) < 1:\n",
        "            print(\"Warning: No documents for fine-tuning BERT. Skipping.\")\n",
        "            return\n",
        "\n",
        "        # Create paired InputExamples (anchor and positive are the same document)\n",
        "        examples = []\n",
        "        for doc in documents:\n",
        "            examples.append(InputExample(texts=[doc, doc], label=1.0))\n",
        "        train_dataloader = DataLoader(examples, shuffle=True, batch_size=8)\n",
        "\n",
        "        train_loss = losses.CosineSimilarityLoss(self.bert_model)\n",
        "        self.bert_model.fit(\n",
        "            train_objectives=[(train_dataloader, train_loss)],\n",
        "            epochs=self.fine_tune_steps // len(documents) + 1,\n",
        "            warmup_steps=10,\n",
        "            output_path=\"fine_tuned_bert_model\",\n",
        "            use_amp=False\n",
        "        )\n",
        "\n",
        "    def reduce_dimensions(self, embeddings):\n",
        "        \"\"\"Apply UMAP or PCA dimensionality reduction\"\"\"\n",
        "        if UMAP_AVAILABLE:\n",
        "            self.reducer = UMAP(n_components=50, random_state=42, n_neighbors=15, min_dist=0.1)\n",
        "            return self.reducer.fit_transform(embeddings)\n",
        "        else:\n",
        "            print(\"Using PCA for dimensionality reduction\")\n",
        "            self.reducer = PCA(n_components=50, random_state=42)\n",
        "            return self.reducer.fit_transform(embeddings)\n",
        "\n",
        "    def cluster_documents(self, reduced_embeddings):\n",
        "        \"\"\"Cluster documents using reduced embeddings\"\"\"\n",
        "        self.cluster_model = KMeans(n_clusters=self.n_topics, random_state=42)\n",
        "        return self.cluster_model.fit_predict(reduced_embeddings)\n",
        "\n",
        "    def train_global_lda(self, documents):\n",
        "        \"\"\"Train global LDA model as fallback\"\"\"\n",
        "        academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section',\n",
        "                               'example', 'problem', 'solution', 'study', 'learn']\n",
        "        self.global_vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english',\n",
        "                                                 ngram_range=(1, 2), max_features=1000)\n",
        "        self.global_vectorizer.stop_words_ = set(list(self.global_vectorizer.get_stop_words()) + academic_stop_words)\n",
        "        dtm = self.global_vectorizer.fit_transform(documents)\n",
        "\n",
        "        self.global_lda_model = LatentDirichletAllocation(\n",
        "            n_components=self.n_topics,\n",
        "            random_state=42,\n",
        "            max_iter=15\n",
        "        )\n",
        "        self.global_lda_model.fit(dtm)\n",
        "        return self.global_lda_model\n",
        "\n",
        "    def train_lda_per_cluster(self, documents, clusters):\n",
        "        \"\"\"Train separate LDA models for each cluster\"\"\"\n",
        "        for cluster_id in range(self.n_topics):\n",
        "            cluster_docs = [doc for i, doc in enumerate(documents) if clusters[i] == cluster_id]\n",
        "\n",
        "            if len(cluster_docs) < 10:  # Minimum documents threshold\n",
        "                print(f\"Cluster {cluster_id} has too few documents. Using global model.\")\n",
        "                self.cluster_lda_models[cluster_id] = self.global_lda_model\n",
        "                self.cluster_vectorizers[cluster_id] = self.global_vectorizer\n",
        "                continue\n",
        "\n",
        "            # Cluster-specific vectorizer\n",
        "            vectorizer = CountVectorizer(max_df=0.85, min_df=2, stop_words='english',\n",
        "                                         ngram_range=(1, 2), max_features=500)\n",
        "            dtm = vectorizer.fit_transform(cluster_docs)\n",
        "\n",
        "            # Train LDA\n",
        "            lda = LatentDirichletAllocation(\n",
        "                n_components=1,  # Each cluster gets one primary topic\n",
        "                learning_method='online',\n",
        "                random_state=42,\n",
        "                max_iter=10\n",
        "            )\n",
        "            lda.fit(dtm)\n",
        "\n",
        "            self.cluster_lda_models[cluster_id] = lda\n",
        "            self.cluster_vectorizers[cluster_id] = vectorizer\n",
        "\n",
        "    def compute_topic_embeddings(self, documents):\n",
        "        \"\"\"Optimized topic embedding calculation with adaptive topic count and MMR diversification\"\"\"\n",
        "        # Get BERT embeddings and reduce dimensions\n",
        "        bert_embeddings = self.bert_model.encode(documents)\n",
        "        reduced_embeddings = self.reduce_dimensions(bert_embeddings)\n",
        "\n",
        "        # Cluster documents using HDBSCAN or KMeans\n",
        "        if HDBSCAN_AVAILABLE:\n",
        "            try:\n",
        "                cluster_model = HDBSCAN(min_cluster_size=10, gen_min_span_tree=True)\n",
        "                clusters = cluster_model.fit_predict(reduced_embeddings)\n",
        "                n_clusters = len(np.unique(clusters)) - (1 if -1 in clusters else 0)\n",
        "                self.n_topics = max(3, min(n_clusters, 10))\n",
        "                self.cluster_model = cluster_model\n",
        "                self.clusters = clusters\n",
        "                print(f\"HDBSCAN found {n_clusters} clusters\")\n",
        "            except Exception as e:\n",
        "                print(f\"HDBSCAN failed: {str(e)}. Using KMeans.\")\n",
        "                self._cluster_with_kmeans(reduced_embeddings)\n",
        "        else:\n",
        "            self._cluster_with_kmeans(reduced_embeddings)\n",
        "\n",
        "        # Adaptive topic count optimization using coherence\n",
        "        best_coherence = float('-inf')  # Initialize to negative infinity\n",
        "        best_lda = None\n",
        "        best_vectorizer = None\n",
        "        optimal_topics = self.n_topics  # Initialize with current cluster count\n",
        "\n",
        "        # Define topic range safely\n",
        "        min_topics = max(2, self.n_topics - 2)\n",
        "        max_topics = min(self.n_topics + 3, 15)\n",
        "        topic_range = range(min_topics, max_topics + 1)\n",
        "\n",
        "        print(f\"Optimizing LDA topic count in range {list(topic_range)}...\")\n",
        "        for n in topic_range:\n",
        "            # Train temporary LDA model\n",
        "            academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section',\n",
        "                                   'example', 'problem', 'solution', 'study', 'learn']\n",
        "            vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english',\n",
        "                                         ngram_range=(1, 2), max_features=1000)\n",
        "            vectorizer.stop_words_ = set(list(vectorizer.get_stop_words()) + academic_stop_words)\n",
        "            dtm = vectorizer.fit_transform(documents)\n",
        "\n",
        "            lda = LatentDirichletAllocation(\n",
        "                n_components=n,\n",
        "                learning_method='online',\n",
        "                random_state=42,\n",
        "                max_iter=10\n",
        "            )\n",
        "            lda.fit(dtm)\n",
        "\n",
        "            # Calculate coherence\n",
        "            coherence = self.calculate_coherence(lda, vectorizer, documents)\n",
        "            print(f\"  Topics={n} | Coherence={coherence:.3f}\")\n",
        "\n",
        "            if coherence > best_coherence:\n",
        "                best_coherence = coherence\n",
        "                best_lda = lda\n",
        "                best_vectorizer = vectorizer\n",
        "                optimal_topics = n  # Update optimal topic count\n",
        "\n",
        "        # Set best models\n",
        "        self.global_lda_model = best_lda\n",
        "        self.global_vectorizer = best_vectorizer\n",
        "        print(f\"Selected LDA model with {optimal_topics} topics (Coherence={best_coherence:.3f})\")\n",
        "\n",
        "        # Create enhanced topic embeddings with MMR diversification\n",
        "        self.topic_embeddings = []\n",
        "        unique_clusters = np.unique(self.clusters)\n",
        "\n",
        "        for cluster_id in unique_clusters:\n",
        "            if cluster_id == -1:\n",
        "                continue  # Skip noise points\n",
        "\n",
        "            # Get cluster documents\n",
        "            cluster_mask = (self.clusters == cluster_id)\n",
        "            cluster_docs = [doc for i, doc in enumerate(documents) if cluster_mask[i]]\n",
        "\n",
        "            # Get cluster centroid\n",
        "            cluster_embeddings = bert_embeddings[cluster_mask]\n",
        "            centroid = np.mean(cluster_embeddings, axis=0) if len(cluster_embeddings) > 0 else np.mean(bert_embeddings,\n",
        "                                                                                                       axis=0)\n",
        "\n",
        "            # Get candidate terms using TF-IDF\n",
        "            if cluster_docs:\n",
        "                try:\n",
        "                    # Get top candidate terms from cluster documents\n",
        "                    candidate_terms = self.get_candidate_terms(cluster_docs)\n",
        "\n",
        "                    # Apply MMR diversification\n",
        "                    selected_terms = self.mmr_diversification(\n",
        "                        centroid,\n",
        "                        candidate_terms,\n",
        "                        self.bert_model,\n",
        "                        diversity_factor=0.7,\n",
        "                        top_n=15\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    print(f\"Term selection failed for cluster {cluster_id}: {str(e)}\")\n",
        "                    selected_terms = self._get_global_topic_words(cluster_id)\n",
        "            else:\n",
        "                selected_terms = self._get_global_topic_words(cluster_id)\n",
        "\n",
        "            # Encode selected terms\n",
        "            if selected_terms:\n",
        "                try:\n",
        "                    word_embeddings = self.bert_model.encode(selected_terms)\n",
        "                    word_avg = np.mean(word_embeddings, axis=0)\n",
        "                except:\n",
        "                    word_avg = centroid\n",
        "            else:\n",
        "                word_avg = centroid\n",
        "\n",
        "            # Combine embeddings\n",
        "            combined_embedding = 0.85 * centroid + 0.15 * word_avg\n",
        "            self.topic_embeddings.append(combined_embedding)\n",
        "\n",
        "        self.topic_embeddings = np.array(self.topic_embeddings)\n",
        "        return self.topic_embeddings\n",
        "\n",
        "    def _cluster_with_kmeans(self, reduced_embeddings):\n",
        "        \"\"\"Cluster using KMeans as fallback\"\"\"\n",
        "        self.cluster_model = KMeans(n_clusters=self.n_topics, random_state=42)\n",
        "        self.clusters = self.cluster_model.fit_predict(reduced_embeddings)\n",
        "        print(f\"Using KMeans with {self.n_topics} clusters\")\n",
        "\n",
        "    def _get_global_topic_words(self, cluster_id):\n",
        "        \"\"\"Get top words from global LDA\"\"\"\n",
        "        cluster_idx = min(cluster_id, self.global_lda_model.components_.shape[0]-1)\n",
        "        top_indices = self.global_lda_model.components_[cluster_idx].argsort()[::-1][:20]\n",
        "        return [self.global_vectorizer.get_feature_names_out()[i] for i in top_indices]\n",
        "\n",
        "    def get_document_topic_distribution(self, documents):\n",
        "        \"\"\"Improved distribution using semantic similarity with contextual weighting\"\"\"\n",
        "        doc_embeddings = self.bert_model.encode(documents)\n",
        "        semantic_sim = cosine_similarity(doc_embeddings, self.topic_embeddings)\n",
        "\n",
        "        # Get cluster probabilities\n",
        "        reduced_embeddings = self.reducer.transform(doc_embeddings)\n",
        "        cluster_probs = self._get_cluster_probabilities(reduced_embeddings)\n",
        "\n",
        "        # Combine with contextual weighting\n",
        "        hybrid_dist = 0.75 * semantic_sim + 0.25 * cluster_probs\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        temperature = 0.7\n",
        "        scaled_dist = np.exp(hybrid_dist / temperature)\n",
        "        return scaled_dist / np.sum(scaled_dist, axis=1, keepdims=True)\n",
        "\n",
        "    def _get_cluster_probabilities(self, embeddings):\n",
        "        \"\"\"Get soft cluster probabilities\"\"\"\n",
        "        if hasattr(self.cluster_model, 'predict_proba'):\n",
        "            return self.cluster_model.predict_proba(embeddings)\n",
        "        else:\n",
        "            # Create soft clustering for KMeans\n",
        "            distances = self.cluster_model.transform(embeddings)\n",
        "            return 1 / (1 + distances)\n",
        "\n",
        "    def get_dominant_topic(self, documents):\n",
        "        \"\"\"Extract dominant topic\"\"\"\n",
        "        hybrid_dist = self.get_document_topic_distribution(documents)\n",
        "        return np.argmax(hybrid_dist, axis=1)\n",
        "\n",
        "    # Helper methods needed in the class:\n",
        "    def calculate_coherence(self, lda_model, vectorizer, documents):\n",
        "        \"\"\"Calculate topic coherence using UMass measure with sparse matrix support\"\"\"\n",
        "        # Get topic terms\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "        topics = []\n",
        "        for topic_idx in range(lda_model.n_components):\n",
        "            top_indices = lda_model.components_[topic_idx].argsort()[::-1][:10]\n",
        "            topics.append([feature_names[i] for i in top_indices])\n",
        "\n",
        "        # Prepare document-term matrix\n",
        "        dtm = vectorizer.transform(documents)\n",
        "\n",
        "        # Calculate pairwise coherence\n",
        "        total_coherence = 0\n",
        "        valid_topics = 0\n",
        "\n",
        "        for topic in topics:\n",
        "            topic_coherence = 0\n",
        "            valid_pairs = 0\n",
        "\n",
        "            for i in range(1, len(topic)):\n",
        "                for j in range(0, i):\n",
        "                    # Get vocabulary indices\n",
        "                    try:\n",
        "                        idx_i = vectorizer.vocabulary_[topic[j]]\n",
        "                        idx_j = vectorizer.vocabulary_[topic[i]]\n",
        "                    except KeyError:\n",
        "                        continue\n",
        "\n",
        "                    # Get co-occurrence statistics using sparse matrix operations\n",
        "                    # Count documents containing term i\n",
        "                    D_wi = (dtm[:, idx_i] != 0).sum()\n",
        "\n",
        "                    # Count documents containing both terms i and j\n",
        "                    # Create binary masks for each term\n",
        "                    term_i_mask = (dtm[:, idx_i] != 0).astype(int)\n",
        "                    term_j_mask = (dtm[:, idx_j] != 0).astype(int)\n",
        "\n",
        "                    # Calculate co-occurrence using dot product\n",
        "                    D_wi_wj = term_i_mask.multiply(term_j_mask).sum()\n",
        "\n",
        "                    # Avoid division by zero\n",
        "                    if D_wi > 0 and D_wi_wj > 0:\n",
        "                        score = np.log((D_wi_wj + 1.0) / D_wi)\n",
        "                        topic_coherence += score\n",
        "                        valid_pairs += 1\n",
        "\n",
        "            # Only count topics with valid pairs\n",
        "            if valid_pairs > 0:\n",
        "                total_coherence += topic_coherence / valid_pairs\n",
        "                valid_topics += 1\n",
        "\n",
        "        # Return average coherence across valid topics\n",
        "        return total_coherence / valid_topics if valid_topics > 0 else 0\n",
        "\n",
        "    def get_candidate_terms(self, cluster_docs, top_n=100):\n",
        "        \"\"\"Get top candidate terms from cluster documents using TF-IDF\"\"\"\n",
        "        vectorizer = TfidfVectorizer(max_features=top_n, stop_words='english')\n",
        "        try:\n",
        "            tfidf = vectorizer.fit_transform(cluster_docs)\n",
        "            feature_names = vectorizer.get_feature_names_out()\n",
        "            word_scores = tfidf.sum(axis=0).A1\n",
        "            top_indices = word_scores.argsort()[::-1][:top_n]\n",
        "            return [feature_names[i] for i in top_indices]\n",
        "        except ValueError:\n",
        "            return []\n",
        "\n",
        "    def mmr_diversification(self, centroid, terms, bert_model, diversity_factor=0.7, top_n=15):\n",
        "        \"\"\"Maximal Marginal Relevance for diverse term selection\"\"\"\n",
        "        if not terms:\n",
        "            return []\n",
        "\n",
        "        # Encode all terms at once\n",
        "        term_embeddings = bert_model.encode(terms)\n",
        "\n",
        "        # Calculate similarity to centroid\n",
        "        centroid_sim = cosine_similarity([centroid], term_embeddings)[0]\n",
        "\n",
        "        selected_indices = []\n",
        "        selected_terms = []\n",
        "\n",
        "        # Start with most relevant term\n",
        "        first_idx = np.argmax(centroid_sim)\n",
        "        selected_indices.append(first_idx)\n",
        "        selected_terms.append(terms[first_idx])\n",
        "\n",
        "        # Iteratively select remaining terms\n",
        "        while len(selected_terms) < min(top_n, len(terms)):\n",
        "            candidate_indices = set(range(len(terms))) - set(selected_indices)\n",
        "            if not candidate_indices:\n",
        "                break\n",
        "\n",
        "            mmr_scores = []\n",
        "            for idx in candidate_indices:\n",
        "                # Relevance to centroid\n",
        "                rel_score = centroid_sim[idx]\n",
        "\n",
        "                # Max similarity to selected terms\n",
        "                max_sim = 0\n",
        "                if selected_indices:\n",
        "                    sims = cosine_similarity(\n",
        "                        [term_embeddings[idx]],\n",
        "                        [term_embeddings[i] for i in selected_indices]\n",
        "                    )\n",
        "                    max_sim = np.max(sims)\n",
        "\n",
        "                # MMR calculation\n",
        "                mmr = diversity_factor * rel_score - (1 - diversity_factor) * max_sim\n",
        "                mmr_scores.append((idx, mmr))\n",
        "\n",
        "            # Select term with highest MMR\n",
        "            next_idx = max(mmr_scores, key=lambda x: x[1])[0]\n",
        "            selected_indices.append(next_idx)\n",
        "            selected_terms.append(terms[next_idx])\n",
        "\n",
        "        return selected_terms\n",
        "\n",
        "    def _get_cluster_probabilities(self, embeddings):\n",
        "        \"\"\"Robust cluster probability calculation for all clustering methods\"\"\"\n",
        "        # 1. Models with predict_proba method\n",
        "        if hasattr(self.cluster_model, 'predict_proba'):\n",
        "            try:\n",
        "                return self.cluster_model.predict_proba(embeddings)\n",
        "            except Exception as e:\n",
        "                print(f\"Predict_proba failed: {str(e)}. Using fallback.\")\n",
        "\n",
        "        # 2. HDBSCAN-specific handling\n",
        "        if HDBSCAN_AVAILABLE and isinstance(self.cluster_model, HDBSCAN):\n",
        "            try:\n",
        "                # Get soft clusters for HDBSCAN\n",
        "                return self.cluster_model.membership_vector(embeddings)\n",
        "            except Exception as e:\n",
        "                print(f\"HDBSCAN membership_vector failed: {str(e)}\")\n",
        "\n",
        "        # 3. KMeans/GMM fallback\n",
        "        if hasattr(self.cluster_model, 'transform'):\n",
        "            try:\n",
        "                # Soft clustering via distance transform\n",
        "                distances = self.cluster_model.transform(embeddings)\n",
        "                return 1 / (1 + distances)\n",
        "            except Exception as e:\n",
        "                print(f\"Distance transform failed: {str(e)}\")\n",
        "\n",
        "        # 4. Final fallback: one-hot encoding from labels\n",
        "        try:\n",
        "            labels = self.cluster_model.predict(embeddings)\n",
        "            n_clusters = len(np.unique(labels))\n",
        "            probs = np.zeros((len(embeddings), n_clusters))\n",
        "            probs[np.arange(len(embeddings)), labels] = 1\n",
        "            return probs\n",
        "        except Exception as e:\n",
        "            print(f\"One-hot encoding failed: {str(e)}\")\n",
        "            # Uniform distribution as last resort\n",
        "            return np.ones((len(embeddings), self.n_topics)) / self.n_topics\n",
        "\n",
        "# ========================\n",
        "# 2. TOPIC MODEL EVALUATION\n",
        "# ========================\n",
        "\n",
        "class TopicModelEvaluator:\n",
        "    \"\"\"Evaluates multiple topic models using coherence and diversity metrics\"\"\"\n",
        "\n",
        "    def __init__(self, documents, n_topics=5):\n",
        "        self.documents = documents\n",
        "        self.n_topics = n_topics\n",
        "        self.tokenized_docs = self._tokenize_documents(documents)\n",
        "        self.dictionary = self._create_dictionary() if GENSIM_AVAILABLE else None\n",
        "        self.visualizer = ResultVisualizer()  # Initialize visualizer here\n",
        "\n",
        "    def _tokenize_documents(self, documents):\n",
        "        \"\"\"Tokenize documents using nltk or fallback\"\"\"\n",
        "        try:\n",
        "            from nltk.tokenize import word_tokenize\n",
        "            return [word_tokenize(doc.lower()) for doc in documents]\n",
        "        except ImportError:\n",
        "            return [doc.lower().split() for doc in documents]\n",
        "\n",
        "    def _calculate_topic_quality(self, topics):\n",
        "        \"\"\"Robust topic quality calculation with comprehensive error handling\"\"\"\n",
        "        # Initialize default metrics\n",
        "        metrics = {\n",
        "            \"coherence\": 0.5,\n",
        "            \"distinctiveness\": 0.0,\n",
        "            \"relevance\": 0.0\n",
        "        }\n",
        "\n",
        "        # Validate topics input\n",
        "        if not topics or not isinstance(topics, list) or len(topics) == 0:\n",
        "            print(\"Warning: Invalid topics format. Returning default metrics.\")\n",
        "            return metrics\n",
        "\n",
        "        # 1. Topic coherence calculation\n",
        "        metrics[\"coherence\"] = self._calculate_coherence(topics)\n",
        "\n",
        "        # 2. Topic distinctiveness\n",
        "        try:\n",
        "            unique_words = set()\n",
        "            total_words = 0\n",
        "            for topic in topics:\n",
        "                if not topic:  # Skip empty topics\n",
        "                    continue\n",
        "                for word in topic:\n",
        "                    if word:  # Skip empty strings\n",
        "                        unique_words.add(word)\n",
        "                        total_words += 1\n",
        "            metrics[\"distinctiveness\"] = len(unique_words) / total_words if total_words > 0 else 0.0\n",
        "        except Exception as e:\n",
        "            print(f\"Distinctiveness calculation failed: {str(e)}\")\n",
        "            metrics[\"distinctiveness\"] = 0.0\n",
        "\n",
        "        # 3. Term relevance (IDF-weighted)\n",
        "        try:\n",
        "            from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "            # Handle empty documents\n",
        "            if not self.documents or len(self.documents) == 0:\n",
        "                print(\"Warning: No documents for relevance calculation.\")\n",
        "                return metrics\n",
        "\n",
        "            vectorizer = TfidfVectorizer()\n",
        "            try:\n",
        "                tfidf = vectorizer.fit_transform(self.documents)\n",
        "                idf = vectorizer.idf_\n",
        "                vocab = vectorizer.get_feature_names_out()\n",
        "            except ValueError:\n",
        "                # Fallback for small documents\n",
        "                print(\"Using fallback TF-IDF for small document set\")\n",
        "                vectorizer = TfidfVectorizer(min_df=1)\n",
        "                tfidf = vectorizer.fit_transform(self.documents)\n",
        "                idf = vectorizer.idf_\n",
        "                vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "            relevance_scores = []\n",
        "            for topic in topics:\n",
        "                if not topic:  # Skip empty topics\n",
        "                    continue\n",
        "\n",
        "                topic_score = 0.0\n",
        "                valid_terms = 0\n",
        "\n",
        "                for term in topic:\n",
        "                    if term and term in vocab:  # Check for non-empty term\n",
        "                        try:\n",
        "                            idx = np.where(vocab == term)[0][0]\n",
        "                            topic_score += idf[idx]\n",
        "                            valid_terms += 1\n",
        "                        except IndexError:\n",
        "                            pass\n",
        "\n",
        "                if valid_terms > 0:\n",
        "                    relevance_scores.append(topic_score / valid_terms)\n",
        "\n",
        "            metrics[\"relevance\"] = np.mean(relevance_scores) if relevance_scores else 0.0\n",
        "        except Exception as e:\n",
        "            print(f\"Relevance calculation failed: {str(e)}\")\n",
        "            metrics[\"relevance\"] = 0.0\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def _create_dictionary(self):\n",
        "        \"\"\"Create gensim dictionary with filtering\"\"\"\n",
        "        if not GENSIM_AVAILABLE:\n",
        "            return None\n",
        "        dictionary = Dictionary(self.tokenized_docs)\n",
        "        dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
        "        return dictionary\n",
        "\n",
        "    def _calculate_coherence(self, topics):\n",
        "        \"\"\"Reliable coherence calculation with multiple fallbacks\"\"\"\n",
        "        # Validate input\n",
        "        if not topics or any(len(t) == 0 for t in topics):\n",
        "            return 0.5\n",
        "\n",
        "        # Attempt c_v coherence\n",
        "        try:\n",
        "            dictionary = Dictionary(self.tokenized_docs)\n",
        "            dictionary.filter_extremes(no_below=3, no_above=0.8)\n",
        "            coherence_model = CoherenceModel(\n",
        "                topics=topics,\n",
        "                texts=self.tokenized_docs,\n",
        "                dictionary=dictionary,\n",
        "                coherence='c_v'\n",
        "            )\n",
        "            return max(0, min(1.0, coherence_model.get_coherence()))\n",
        "        except Exception as e:\n",
        "            print(f\"c_v coherence failed: {str(e)}\")\n",
        "\n",
        "        # Attempt u_mass coherence\n",
        "        try:\n",
        "            corpus = [dictionary.doc2bow(doc) for doc in self.tokenized_docs]\n",
        "            coherence_model = CoherenceModel(\n",
        "                topics=topics,\n",
        "                corpus=corpus,\n",
        "                dictionary=dictionary,\n",
        "                coherence='u_mass'\n",
        "            )\n",
        "            u_mass = coherence_model.get_coherence()\n",
        "            # Convert to 0-1 scale (approximate)\n",
        "            return min(1.0, max(0, (u_mass + 10) / 20))\n",
        "        except Exception as e:\n",
        "            print(f\"u_mass coherence failed: {str(e)}\")\n",
        "\n",
        "        # Fallback to simple metric\n",
        "        return self._simple_topic_coherence(topics)\n",
        "\n",
        "    def _simple_topic_coherence(self, topics):\n",
        "        \"\"\"Fallback coherence metric based on PMI\"\"\"\n",
        "        from itertools import combinations\n",
        "        from collections import defaultdict\n",
        "\n",
        "        # Create document frequency map\n",
        "        doc_freq = defaultdict(int)\n",
        "        cooc_freq = defaultdict(int)\n",
        "\n",
        "        for doc in self.tokenized_docs:\n",
        "            unique_words = set(doc)\n",
        "            for word in unique_words:\n",
        "                doc_freq[word] += 1\n",
        "            for w1, w2 in combinations(unique_words, 2):\n",
        "                cooc_freq[(w1, w2)] += 1\n",
        "\n",
        "        # Calculate average pairwise PMI\n",
        "        topic_coherence = []\n",
        "        for topic in topics:\n",
        "            topic = [word for word in topic if word in doc_freq]\n",
        "            if len(topic) < 2:\n",
        "                continue\n",
        "\n",
        "            pmi_scores = []\n",
        "            for (w1, w2) in combinations(topic, 2):\n",
        "                if (w1, w2) in cooc_freq:\n",
        "                    p_w1w2 = cooc_freq[(w1, w2)] / len(self.tokenized_docs)\n",
        "                    p_w1 = doc_freq[w1] / len(self.tokenized_docs)\n",
        "                    p_w2 = doc_freq[w2] / len(self.tokenized_docs)\n",
        "                    pmi = np.log(p_w1w2 / (p_w1 * p_w2))\n",
        "                    pmi_scores.append(pmi)\n",
        "\n",
        "            if pmi_scores:\n",
        "                topic_coherence.append(np.mean(pmi_scores))\n",
        "\n",
        "        # Normalize to 0-1 scale\n",
        "        if topic_coherence:\n",
        "            max_pmi = max(topic_coherence)\n",
        "            return min(1.0, max(0, np.mean(topic_coherence) / max_pmi if max_pmi > 0 else 0))\n",
        "        return 0.5\n",
        "\n",
        "    def _calculate_diversity(self, topics):\n",
        "        \"\"\"Calculate topic diversity metric\"\"\"\n",
        "        unique_words = set()\n",
        "        total_words = 0\n",
        "        for topic in topics:\n",
        "            for word in topic:\n",
        "                unique_words.add(word)\n",
        "                total_words += 1\n",
        "        return len(unique_words) / total_words if total_words > 0 else 0\n",
        "\n",
        "    def evaluate_hybrid_model(self, hybrid_model):\n",
        "        \"\"\"Enhanced evaluation for both hybrid models\"\"\"\n",
        "        enhanced_topics = []\n",
        "        n_topics = hybrid_model.n_topics\n",
        "\n",
        "        # Get topic terms based on model type\n",
        "        if hasattr(hybrid_model, 'global_vectorizer') and hybrid_model.global_vectorizer is not None:\n",
        "            # Enhanced hybrid model\n",
        "            feature_names = hybrid_model.global_vectorizer.get_feature_names_out()\n",
        "            top_indices = hybrid_model.global_lda_model.components_.argsort(axis=1)[:, ::-1][:, :10]\n",
        "        else:\n",
        "            # Original hybrid model\n",
        "            feature_names = hybrid_model.vectorizer.get_feature_names_out()\n",
        "            top_indices = hybrid_model.lda_model.components_.argsort(axis=1)[:, ::-1][:, :10]\n",
        "\n",
        "        topic_terms = [feature_names[i] for row in top_indices for i in row]\n",
        "\n",
        "        for i in range(n_topics):\n",
        "            # Slice terms for the current topic\n",
        "            start_idx = i * 10\n",
        "            end_idx = start_idx + 10\n",
        "            terms = topic_terms[start_idx:end_idx]\n",
        "\n",
        "            # Get topic embedding\n",
        "            topic_embedding = hybrid_model.topic_embeddings[i]\n",
        "\n",
        "            # Find representative documents\n",
        "            doc_embeddings = hybrid_model.bert_model.encode(self.documents)\n",
        "            doc_sims = cosine_similarity([topic_embedding], doc_embeddings)[0]\n",
        "            top_doc_idx = np.argsort(doc_sims)[-5:]  # Top 5 documents\n",
        "            top_docs = [self.documents[i] for i in top_doc_idx]\n",
        "\n",
        "            # Extract meaningful nouns\n",
        "            nouns = [w for doc in top_docs for w in doc.split() if len(w) > 3 and w.isalpha()]\n",
        "            counter = Counter(nouns)\n",
        "\n",
        "            # Add new relevant terms\n",
        "            terms_list = list(terms)\n",
        "            new_terms = [word for word, _ in counter.most_common(3) if word not in terms_list]\n",
        "\n",
        "            if not new_terms:\n",
        "                enhanced_terms = terms[:7]  # Use top 7 terms if no new terms\n",
        "            else:\n",
        "                padded_new_terms = new_terms[:3] + [''] * (3 - len(new_terms))\n",
        "                enhanced_terms = terms[:7] + padded_new_terms[:3]\n",
        "\n",
        "            enhanced_topics.append(enhanced_terms)\n",
        "\n",
        "        return enhanced_topics\n",
        "\n",
        "    def evaluate_enhanced_hybrid_model(self, hybrid_model):\n",
        "        \"\"\"Evaluation specifically for the paper-inspired hybrid model\"\"\"\n",
        "        topics = []\n",
        "        n_topics = hybrid_model.n_topics\n",
        "\n",
        "        # Get top words from global LDA\n",
        "        feature_names = hybrid_model.global_vectorizer.get_feature_names_out()\n",
        "\n",
        "        for i in range(n_topics):\n",
        "            top_indices = hybrid_model.global_lda_model.components_[i].argsort()[::-1][:10]\n",
        "            topics.append([feature_names[idx] for idx in top_indices])\n",
        "\n",
        "        return topics\n",
        "\n",
        "    def evaluate_bert_model(self, documents):\n",
        "        \"\"\"Evaluate BERT-based topic modeling\"\"\"\n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        embeddings = model.encode(documents)\n",
        "        kmeans = KMeans(n_clusters=self.n_topics, random_state=42)\n",
        "        clusters = kmeans.fit_predict(embeddings)\n",
        "        vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "        vectorizer.fit(documents)\n",
        "        vocabulary = vectorizer.get_feature_names_out()\n",
        "        topics = []\n",
        "        for i in range(self.n_topics):\n",
        "            cluster_docs = [documents[j] for j in range(len(documents)) if clusters[j] == i]\n",
        "            if not cluster_docs:\n",
        "                topics.append([])\n",
        "                continue\n",
        "            cluster_tfidf = vectorizer.transform(cluster_docs)\n",
        "            word_scores = cluster_tfidf.sum(axis=0).A1\n",
        "            top_indices = word_scores.argsort()[-10:][::-1]\n",
        "            topics.append([vocabulary[idx] for idx in top_indices])\n",
        "        return topics\n",
        "\n",
        "    def train_global_lda(self, documents):\n",
        "        \"\"\"Train global LDA model as fallback\"\"\"\n",
        "        academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section',\n",
        "                               'example', 'problem', 'solution', 'study', 'learn']\n",
        "        self.global_vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english',\n",
        "                                                 ngram_range=(1, 2), max_features=1000)\n",
        "        self.global_vectorizer.stop_words_ = set(list(self.global_vectorizer.get_stop_words()) + academic_stop_words)\n",
        "        dtm = self.global_vectorizer.fit_transform(documents)\n",
        "\n",
        "        self.global_lda_model = LatentDirichletAllocation(\n",
        "            n_components=self.n_topics,\n",
        "            random_state=42,\n",
        "            max_iter=15\n",
        "        )\n",
        "        self.global_lda_model.fit(dtm)\n",
        "        return self.global_lda_model\n",
        "\n",
        "    def train_lda_per_cluster(self, documents, clusters):\n",
        "        \"\"\"Train separate LDA models for each cluster\"\"\"\n",
        "        for cluster_id in range(self.n_topics):\n",
        "            cluster_docs = [doc for i, doc in enumerate(documents) if clusters[i] == cluster_id]\n",
        "\n",
        "            if len(cluster_docs) < 10:  # Minimum documents threshold\n",
        "                print(f\"Cluster {cluster_id} has too few documents. Using global model.\")\n",
        "                self.cluster_lda_models[cluster_id] = self.global_lda_model\n",
        "                self.cluster_vectorizers[cluster_id] = self.global_vectorizer\n",
        "                continue\n",
        "\n",
        "            # Cluster-specific vectorizer\n",
        "            vectorizer = CountVectorizer(max_df=0.85, min_df=2, stop_words='english',\n",
        "                                         ngram_range=(1, 2), max_features=500)\n",
        "            dtm = vectorizer.fit_transform(cluster_docs)\n",
        "\n",
        "            # Train LDA\n",
        "            lda = LatentDirichletAllocation(\n",
        "                n_components=1,  # Each cluster gets one primary topic\n",
        "                learning_method='online',\n",
        "                random_state=42,\n",
        "                max_iter=10\n",
        "            )\n",
        "            lda.fit(dtm)\n",
        "\n",
        "            self.cluster_lda_models[cluster_id] = lda\n",
        "            self.cluster_vectorizers[cluster_id] = vectorizer\n",
        "\n",
        "\n",
        "    def train_lda(self, documents):\n",
        "        # FIXED: Properly handle NumPy arrays\n",
        "        if documents is None or len(documents) == 0:\n",
        "            print(\"Warning: No documents for LDA training. Using default model.\")\n",
        "            self.lda_model = LatentDirichletAllocation(n_components=self.n_topics, random_state=42)\n",
        "            return\n",
        "\n",
        "        academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section', 'example', 'problem', 'solution', 'study', 'learn']\n",
        "        self.vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english', ngram_range=(1, 2), max_features=1000)\n",
        "        self.vectorizer.stop_words_ = set(list(self.vectorizer.get_stop_words()) + academic_stop_words)\n",
        "        dtm = self.vectorizer.fit_transform(documents)\n",
        "\n",
        "        if GENSIM_AVAILABLE:\n",
        "            best_coherence = -1\n",
        "            for alpha in [0.1, 0.5, 1.0]:\n",
        "                for eta in [0.01, 0.1]:\n",
        "                    lda = LatentDirichletAllocation(\n",
        "                        n_components=self.n_topics,\n",
        "                        learning_method='online',\n",
        "                        learning_offset=10.,\n",
        "                        random_state=42,\n",
        "                        max_iter=15,\n",
        "                        n_jobs=-1,\n",
        "                        doc_topic_prior=alpha,\n",
        "                        topic_word_prior=eta\n",
        "                    )\n",
        "                    lda.fit(dtm)\n",
        "                    # Extract topics manually for CoherenceModel\n",
        "                    feature_names = self.vectorizer.get_feature_names_out()\n",
        "                    topics = [[feature_names[i] for i in topic.argsort()[:-11:-1]] for topic in lda.components_]\n",
        "                    coherence_model = CoherenceModel(\n",
        "                        topics=topics,\n",
        "                        texts=[doc.split() for doc in documents],\n",
        "                        dictionary=Dictionary([doc.split() for doc in documents]),\n",
        "                        coherence='c_v'\n",
        "                    )\n",
        "                    coherence = coherence_model.get_coherence()\n",
        "                    if coherence > best_coherence:\n",
        "                        best_coherence = coherence\n",
        "                        self.lda_model = lda\n",
        "        else:\n",
        "            print(\"Gensim not available. Using default LDA model.\")\n",
        "            self.lda_model = LatentDirichletAllocation(\n",
        "                n_components=self.n_topics,\n",
        "                random_state=42,\n",
        "                max_iter=15,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            self.lda_model.fit(dtm)\n",
        "\n",
        "        # FIXED TOPIC TERM GENERATION\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "        top_indices = self.lda_model.components_.argsort(axis=1)[:, ::-1][:, :10]\n",
        "        self.topic_terms = [feature_names[i] for row in top_indices for i in row]\n",
        "\n",
        "    def compute_topic_embeddings(self, documents):\n",
        "        \"\"\"Enhanced topic embeddings combining cluster, BERT, and LDA information\"\"\"\n",
        "        # Get BERT embeddings and reduce dimensions\n",
        "        bert_embeddings = self.bert_model.encode(documents)\n",
        "        reduced_embeddings = self.reduce_dimensions(bert_embeddings)\n",
        "\n",
        "        # Cluster documents\n",
        "        clusters = self.cluster_documents(reduced_embeddings)\n",
        "\n",
        "        # Train global LDA as fallback\n",
        "        self.train_global_lda(documents)\n",
        "\n",
        "        # Train cluster-specific LDA models\n",
        "        self.train_lda_per_cluster(documents, clusters)\n",
        "\n",
        "        # Create unified topic embeddings\n",
        "        self.topic_embeddings = []\n",
        "        for cluster_id in range(self.n_topics):\n",
        "            # Get cluster centroid\n",
        "            cluster_mask = (clusters == cluster_id)\n",
        "            cluster_center = np.mean(bert_embeddings[cluster_mask], axis=0) if any(cluster_mask) else np.mean(\n",
        "                bert_embeddings, axis=0)\n",
        "\n",
        "            # Get top words from cluster-specific LDA\n",
        "            lda = self.cluster_lda_models[cluster_id]\n",
        "            vectorizer = self.cluster_vectorizers[cluster_id]\n",
        "            feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "            if lda.components_.shape[0] > 0:\n",
        "                top_words_idx = lda.components_[0].argsort()[::-1][:10]\n",
        "                top_words = [feature_names[i] for i in top_words_idx]\n",
        "            else:\n",
        "                # Fallback to global model\n",
        "                top_words_idx = self.global_lda_model.components_[cluster_id].argsort()[::-1][:10]\n",
        "                top_words = [self.global_vectorizer.get_feature_names_out()[i] for i in top_words_idx]\n",
        "\n",
        "            # Encode top words\n",
        "            word_embeddings = self.bert_model.encode(top_words)\n",
        "            word_avg = np.mean(word_embeddings, axis=0)\n",
        "\n",
        "            # Combine embeddings\n",
        "            combined_embedding = (self.lambda_weight * cluster_center +\n",
        "                                  (1 - self.lambda_weight) * word_avg)\n",
        "            self.topic_embeddings.append(combined_embedding)\n",
        "\n",
        "        self.topic_embeddings = np.array(self.topic_embeddings)\n",
        "\n",
        "    def evaluate_lda_model(self, documents):\n",
        "        \"\"\"Train LDA model and extract topics for evaluation\"\"\"\n",
        "        # Train LDA using existing method\n",
        "        self.train_lda(documents)\n",
        "\n",
        "        # Extract topics from trained model\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "        topics = []\n",
        "        for topic_idx in range(self.lda_model.components_.shape[0]):\n",
        "            top_indices = self.lda_model.components_[topic_idx].argsort()[::-1][:10]\n",
        "            topics.append([feature_names[i] for i in top_indices])\n",
        "        return topics\n",
        "\n",
        "    def run_evaluation(self, hybrid_model):\n",
        "        \"\"\"Run evaluation with enhanced hybrid model\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # Evaluate our enhanced hybrid model\n",
        "        if isinstance(hybrid_model, EnhancedHybridTopicModel):\n",
        "            hybrid_topics = self.evaluate_enhanced_hybrid_model(hybrid_model)\n",
        "        else:\n",
        "            hybrid_topics = self.evaluate_hybrid_model(hybrid_model)\n",
        "\n",
        "        lda_topics = self.evaluate_lda_model(self.documents)\n",
        "        bert_topics = self.evaluate_bert_model(self.documents)\n",
        "\n",
        "        results[\"Hybrid (Ours)\"] = {\"topics\": hybrid_topics, \"metrics\": self._calculate_topic_quality(hybrid_topics)}\n",
        "        results[\"LDA Only\"] = {\"topics\": lda_topics, \"metrics\": self._calculate_topic_quality(lda_topics)}\n",
        "        results[\"BERT Only\"] = {\"topics\": bert_topics, \"metrics\": self._calculate_topic_quality(bert_topics)}\n",
        "\n",
        "        return results\n",
        "\n",
        "    def select_best_model(self, results):\n",
        "        \"\"\"Robust model selection with comprehensive error handling\"\"\"\n",
        "        best_model = None\n",
        "        best_score = -1\n",
        "        best_topics = None\n",
        "\n",
        "        # Default weights\n",
        "        weights = {\n",
        "            \"coherence\": 0.5,\n",
        "            \"distinctiveness\": 0.3,\n",
        "            \"relevance\": 0.2\n",
        "        }\n",
        "\n",
        "        for name, data in results.items():\n",
        "            # Skip models with missing data\n",
        "            if data is None or \"metrics\" not in data or data[\"metrics\"] is None:\n",
        "                print(f\"Warning: Missing metrics for {name}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            metrics = data[\"metrics\"]\n",
        "            if metrics is None:\n",
        "                print(f\"Warning: Metrics are None for {name}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Calculate score with fallbacks\n",
        "            try:\n",
        "                score = 0\n",
        "                for metric, weight in weights.items():\n",
        "                    value = metrics.get(metric, 0)\n",
        "                    score += weight * value\n",
        "            except Exception as e:\n",
        "                print(f\"Score calculation failed for {name}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_model = name\n",
        "                best_topics = data.get(\"topics\", [])\n",
        "\n",
        "        if best_model is None:\n",
        "            print(\"Error: No valid models found. Using first model as fallback.\")\n",
        "            first_model = next(iter(results.keys()))\n",
        "            return first_model, results[first_model].get(\"topics\", [])\n",
        "\n",
        "        print(f\"Selected best model: {best_model} (Score: {best_score:.3f})\")\n",
        "        return best_model, best_topics\n",
        "\n",
        "    def visualize_results(self, results, filename=\"topic_model_comparison.png\"):\n",
        "        \"\"\"Robust visualization with comprehensive error handling\"\"\"\n",
        "        import matplotlib.pyplot as plt\n",
        "        import numpy as np\n",
        "\n",
        "        # Validate input results\n",
        "        if not results or not isinstance(results, dict):\n",
        "            print(\"Error: Invalid results format. Cannot visualize.\")\n",
        "            return\n",
        "\n",
        "        # Filter out invalid models\n",
        "        valid_models = []\n",
        "        metric_values = {m: {} for m in results}\n",
        "\n",
        "        metrics = [\"coherence\", \"distinctiveness\", \"relevance\"]\n",
        "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
        "\n",
        "        # Collect valid data with fallbacks\n",
        "        for model_name, model_data in results.items():\n",
        "            if model_data is None:\n",
        "                print(f\"Warning: Missing data for {model_name}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            if \"metrics\" not in model_data:\n",
        "                print(f\"Warning: Missing metrics for {model_name}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            model_metrics = model_data[\"metrics\"]\n",
        "            if model_metrics is None:\n",
        "                print(f\"Warning: Metrics are None for {model_name}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            valid_models.append(model_name)\n",
        "            for metric in metrics:\n",
        "                # Use 0 as fallback for missing metrics\n",
        "                value = model_metrics.get(metric, 0) if model_metrics else 0\n",
        "                metric_values[model_name][metric] = value\n",
        "\n",
        "        if not valid_models:\n",
        "            print(\"Error: No valid models with metrics to visualize.\")\n",
        "            return\n",
        "\n",
        "        # Create visualization\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        bar_width = 0.25\n",
        "        index = np.arange(len(valid_models))\n",
        "\n",
        "        for i, metric in enumerate(metrics):\n",
        "            values = [metric_values[m].get(metric, 0) for m in valid_models]\n",
        "            ax.bar(index + i * bar_width, values, bar_width,\n",
        "                   label=metric.capitalize(), color=colors[i])\n",
        "\n",
        "        ax.set_xlabel('Models')\n",
        "        ax.set_ylabel('Scores')\n",
        "        ax.set_title('Topic Model Quality Metrics')\n",
        "        ax.set_xticks(index + bar_width)\n",
        "        ax.set_xticklabels(valid_models)\n",
        "        ax.legend()\n",
        "        ax.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def comprehensive_evaluation(self, models_dict):\n",
        "        \"\"\"\n",
        "        Perform comprehensive evaluation of multiple models\n",
        "        models_dict: {'Model Name': model_instance}\n",
        "        Returns detailed comparison report\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "        comparison_data = []\n",
        "\n",
        "        for model_name, model in models_dict.items():\n",
        "            print(f\"\\nEvaluating {model_name}...\")\n",
        "\n",
        "            # Get topics\n",
        "            if model_name == \"LDA Only\":\n",
        "                topics = self.evaluate_lda_model(self.documents)\n",
        "            elif model_name == \"BERT Only\":\n",
        "                topics = self.evaluate_bert_model(self.documents)\n",
        "            else:\n",
        "                topics = self.evaluate_hybrid_model(model) if not isinstance(model,\n",
        "                                                                             EnhancedHybridTopicModel) else self.evaluate_enhanced_hybrid_model(\n",
        "                    model)\n",
        "\n",
        "            # Calculate metrics\n",
        "            metrics = self._calculate_topic_quality(topics)\n",
        "\n",
        "            # Store results\n",
        "            results[model_name] = {\n",
        "                \"topics\": topics,\n",
        "                \"metrics\": metrics\n",
        "            }\n",
        "\n",
        "            # Prepare for detailed comparison\n",
        "            comparison_data.append({\n",
        "                \"Model\": model_name,\n",
        "                \"Coherence\": metrics[\"coherence\"],\n",
        "                \"Distinctiveness\": metrics[\"distinctiveness\"],\n",
        "                \"Relevance\": metrics[\"relevance\"],\n",
        "                \"Overall Score\": 0.5 * metrics[\"coherence\"] + 0.3 * metrics[\"distinctiveness\"] + 0.2 * metrics[\n",
        "                    \"relevance\"]\n",
        "            })\n",
        "\n",
        "            # Print topic samples\n",
        "            print(f\"{model_name} Topics (Sample):\")\n",
        "            for i, topic in enumerate(topics[:3]):  # Show first 3 topics\n",
        "                print(f\"  Topic {i + 1}: {', '.join(topic[:5])}...\")\n",
        "\n",
        "        # Create comparison dataframe\n",
        "        comparison_df = pd.DataFrame(comparison_data)\n",
        "        comparison_df = comparison_df.sort_values(\"Overall Score\", ascending=False)\n",
        "\n",
        "        # Visualize comparison\n",
        "        self.visualize_comparison(comparison_df)\n",
        "\n",
        "        # Generate detailed report\n",
        "        report = self.generate_comparison_report(comparison_df, results)\n",
        "\n",
        "        return comparison_df, report\n",
        "\n",
        "    def visualize_comparison(self, comparison_df):\n",
        "        \"\"\"Create comprehensive visualizations of model comparison\"\"\"\n",
        "        # Metrics comparison\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        metrics = [\"Coherence\", \"Distinctiveness\", \"Relevance\", \"Overall Score\"]\n",
        "\n",
        "        for i, metric in enumerate(metrics):\n",
        "            plt.subplot(2, 2, i + 1)\n",
        "            sns.barplot(x=\"Model\", y=metric, data=comparison_df.sort_values(metric, ascending=False),\n",
        "                        palette=\"viridis\")\n",
        "            plt.title(f\"{metric} Comparison\")\n",
        "            plt.xticks(rotation=15)\n",
        "            plt.tight_layout()\n",
        "\n",
        "        plt.savefig(\"model_metrics_comparison.png\", dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "        # Radar chart\n",
        "        self.visualizer.plot_radar_chart(comparison_df)\n",
        "\n",
        "        # Topic quality scatter plot\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.scatterplot(\n",
        "            x=\"Coherence\",\n",
        "            y=\"Distinctiveness\",\n",
        "            size=\"Overall Score\",\n",
        "            hue=\"Model\",\n",
        "            data=comparison_df,\n",
        "            s=200,\n",
        "            alpha=0.8\n",
        "        )\n",
        "        plt.title(\"Topic Quality Comparison\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.savefig(\"topic_quality_scatter.png\", dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    def generate_comparison_report(self, comparison_df, results):\n",
        "        \"\"\"Generate detailed textual report of model comparison\"\"\"\n",
        "        report_lines = [\n",
        "            \"=\" * 70,\n",
        "            \"TOPIC MODELING PERFORMANCE COMPARISON REPORT\",\n",
        "            \"=\" * 70,\n",
        "            f\"Evaluated on {len(self.documents)} documents\",\n",
        "            f\"Number of topics: {self.n_topics}\",\n",
        "            \"-\" * 70,\n",
        "            \"Overall Ranking:\"\n",
        "        ]\n",
        "\n",
        "        # Ranking\n",
        "        for i, row in comparison_df.iterrows():\n",
        "            report_lines.append(f\"{i + 1}. {row['Model']}: {row['Overall Score']:.3f}\")\n",
        "\n",
        "        # Detailed comparison\n",
        "        report_lines.extend([\n",
        "            \"\\n\" + \"-\" * 70,\n",
        "            \"Detailed Metrics:\",\n",
        "            \"{:<20} {:<12} {:<15} {:<12} {:<12}\".format(\n",
        "                \"Model\", \"Coherence\", \"Distinctiveness\", \"Relevance\", \"Overall\"\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        for _, row in comparison_df.iterrows():\n",
        "            report_lines.append(\"{:<20} {:<12.3f} {:<15.3f} {:<12.3f} {:<12.3f}\".format(\n",
        "                row[\"Model\"], row[\"Coherence\"], row[\"Distinctiveness\"],\n",
        "                row[\"Relevance\"], row[\"Overall Score\"]\n",
        "            ))\n",
        "\n",
        "        # Performance insights\n",
        "        best_model = comparison_df.iloc[0][\"Model\"]\n",
        "        report_lines.extend([\n",
        "            \"\\n\" + \"-\" * 70,\n",
        "            \"Performance Insights:\",\n",
        "            f\"- Best performing model: {best_model}\",\n",
        "            f\"- Coherence range: {comparison_df['Coherence'].min():.3f} - {comparison_df['Coherence'].max():.3f}\",\n",
        "            f\"- Distinctiveness range: {comparison_df['Distinctiveness'].min():.3f} - {comparison_df['Distinctiveness'].max():.3f}\",\n",
        "            f\"- Relevance range: {comparison_df['Relevance'].min():.3f} - {comparison_df['Relevance'].max():.3f}\",\n",
        "            \"-\" * 70\n",
        "        ])\n",
        "\n",
        "        # Recommendations\n",
        "        report_lines.extend([\n",
        "            \"\\nRecommendations:\",\n",
        "            f\"- For coherence-focused applications: Use {comparison_df.sort_values('Coherence', ascending=False).iloc[0]['Model']}\",\n",
        "            f\"- For diverse topics: Use {comparison_df.sort_values('Distinctiveness', ascending=False).iloc[0]['Model']}\",\n",
        "            f\"- For relevant terms: Use {comparison_df.sort_values('Relevance', ascending=False).iloc[0]['Model']}\",\n",
        "            f\"- Overall best model: {best_model}\",\n",
        "            \"=\" * 70\n",
        "        ])\n",
        "\n",
        "        return \"\\n\".join(report_lines)\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 3. DYNAMIC STUDENT CLUSTERING\n",
        "# =============================\n",
        "\n",
        "class StudentClusterer:\n",
        "    \"\"\"Base clusterer with BIC optimization and visualization\"\"\"\n",
        "\n",
        "    def __init__(self, max_clusters=10):\n",
        "        self.max_clusters = max_clusters\n",
        "        self.optimal_k = None\n",
        "        self.gmm = None\n",
        "\n",
        "    def validate_features(self, data):\n",
        "        \"\"\"Ensure data quality for clustering\"\"\"\n",
        "        return data.dropna()\n",
        "\n",
        "    def optimize_cluster_count(self, data):\n",
        "        \"\"\"Use BIC to choose optimal cluster count\"\"\"\n",
        "        data = self.validate_features(data)\n",
        "        bic_scores = []\n",
        "        k_range = range(1, self.max_clusters + 1)\n",
        "\n",
        "        for k in tqdm(k_range, desc=\"Computing BIC\"):\n",
        "            gmm = GaussianMixture(n_components=k, random_state=42)\n",
        "            gmm.fit(data)\n",
        "            bic_scores.append(gmm.bic(data))\n",
        "\n",
        "        # Find optimal k (min BIC)\n",
        "        self.optimal_k = np.argmin(bic_scores) + 1  # +1 because k starts at 1\n",
        "        return self.optimal_k, bic_scores\n",
        "\n",
        "    def fit_gmm(self, data):\n",
        "        \"\"\"Fit GMM with optimal k and return labels\"\"\"\n",
        "        if self.optimal_k is None:\n",
        "            self.optimize_cluster_count(data)\n",
        "\n",
        "        self.gmm = GaussianMixture(n_components=self.optimal_k, random_state=42)\n",
        "        self.gmm.fit(data)\n",
        "        return self.gmm.predict(data)\n",
        "\n",
        "    def plot_bic_curve(self, bic_scores, filename='bic_optimization.png'):\n",
        "        \"\"\"Plot BIC curve for model selection with optimal value marked\"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        k_range = range(1, len(bic_scores) + 1)\n",
        "        plt.plot(k_range, bic_scores, 'bo-', label='BIC')\n",
        "\n",
        "        # Mark optimal value\n",
        "        optimal_k = np.argmin(bic_scores) + 1\n",
        "        min_bic = min(bic_scores)\n",
        "        plt.plot(optimal_k, min_bic, 'ro', markersize=8,\n",
        "                 label=f'Optimal k={optimal_k}')\n",
        "\n",
        "        plt.xlabel('Number of Clusters')\n",
        "        plt.ylabel('BIC Score')\n",
        "        plt.title('BIC for Gaussian Mixture Model')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(filename, dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "class EnhancedStudentClusterer(StudentClusterer):\n",
        "    \"\"\"Improved clustering with silhouette optimization and profile interpretation\"\"\"\n",
        "    \"\"\"Improved clustering with EM convergence monitoring\"\"\"\n",
        "\n",
        "    def __init__(self, max_clusters=10):\n",
        "        super().__init__(max_clusters)\n",
        "        self.cluster_metrics = {}\n",
        "        self.log_likelihoods = []\n",
        "\n",
        "    def validate_clusters(self, data, labels):\n",
        "        \"\"\"Compute multiple validation metrics for cluster quality\"\"\"\n",
        "        return {\n",
        "            \"silhouette\": silhouette_score(data, labels),\n",
        "            \"calinski_harabasz\": calinski_harabasz_score(data, labels),\n",
        "            \"davies_bouldin\": davies_bouldin_score(data, labels)\n",
        "        }\n",
        "\n",
        "    def optimize_cluster_count(self, data):\n",
        "        \"\"\"Use silhouette score instead of BIC for better profile separation\"\"\"\n",
        "        \"\"\"Use silhouette score with EM convergence monitoring\"\"\"\n",
        "        data = super().validate_features(data)\n",
        "\n",
        "        best_score = -1\n",
        "        best_k = 3\n",
        "        silhouette_scores = []\n",
        "        cluster_metrics = []\n",
        "        self.log_likelihoods = []  # Reset log-likelihoods\n",
        "\n",
        "        for k in range(2, self.max_clusters + 1):\n",
        "            # Configure GMM with convergence parameters\n",
        "            gmm = GaussianMixture(\n",
        "                n_components=k,\n",
        "                random_state=42,\n",
        "                max_iter=100,\n",
        "                tol=1e-4,\n",
        "                n_init=3\n",
        "            )\n",
        "\n",
        "            # Fit model and track convergence\n",
        "            gmm.fit(data)\n",
        "            labels = gmm.predict(data)\n",
        "\n",
        "            # Store EM convergence metrics\n",
        "            self.log_likelihoods.append(gmm.lower_bound_)\n",
        "\n",
        "            score = silhouette_score(data, labels)\n",
        "            silhouette_scores.append(score)\n",
        "\n",
        "            metrics = self.validate_clusters(data, labels)\n",
        "            cluster_metrics.append(metrics)\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_k = k\n",
        "                best_metrics = metrics\n",
        "\n",
        "        self.optimal_k = best_k\n",
        "        self.cluster_metrics = cluster_metrics\n",
        "        return self.optimal_k, silhouette_scores\n",
        "\n",
        "\n",
        "    def interpret_clusters(self, score_matrix):\n",
        "        \"\"\"Analyze cluster characteristics to identify performance profiles\"\"\"\n",
        "        \"\"\"Improved cluster profiling with adjusted thresholds\"\"\"\n",
        "        cluster_profiles = []\n",
        "        global_variance = score_matrix['variance'].mean()\n",
        "        global_gap = score_matrix['max_min_gap'].mean()\n",
        "\n",
        "        for cluster_id in sorted(score_matrix['cluster'].unique()):\n",
        "            cluster_data = score_matrix[score_matrix['cluster'] == cluster_id]\n",
        "\n",
        "            profile = {\n",
        "                'cluster': cluster_id,\n",
        "                'size': len(cluster_data),\n",
        "                'overall_avg': cluster_data['overall_performance'].mean(),\n",
        "                'theory_avg': cluster_data['theory_avg'].mean(),\n",
        "                'practical_avg': cluster_data['practical_avg'].mean(),\n",
        "                'variance_avg': cluster_data['variance'].mean(),\n",
        "                'max_min_gap': cluster_data['max_min_gap'].mean(),\n",
        "                'weak_subject_count': cluster_data['weak_subject_count'].mean(),\n",
        "                'profile_type': \"\"\n",
        "            }\n",
        "\n",
        "            # Calculate metrics with new thresholds\n",
        "            gap = abs(profile['theory_avg'] - profile['practical_avg'])\n",
        "            variance_ratio = profile['variance_avg'] / global_variance\n",
        "            gap_ratio = profile['max_min_gap'] / global_gap\n",
        "\n",
        "            # Adjusted thresholds for better profiling\n",
        "            if profile['overall_avg'] > 75:\n",
        "                profile['profile_type'] = \"High Performers\"\n",
        "            elif profile['overall_avg'] < 55:  # Lowered threshold from 50\n",
        "                profile['profile_type'] = \"Low Performers\"\n",
        "            elif gap > 15 or (gap_ratio > 1.5 and gap > 10):  # Stricter thresholds\n",
        "                if profile['theory_avg'] > profile['practical_avg']:\n",
        "                    profile['profile_type'] = \"Theory-Focused\"\n",
        "                else:\n",
        "                    profile['profile_type'] = \"Practice-Focused\"\n",
        "            elif variance_ratio > 1.5 or profile['variance_avg'] > 80:  # reduced threshold\n",
        "                profile['profile_type'] = \"Inconsistent Learners\"\n",
        "            else:\n",
        "                profile['profile_type'] = \"Balanced Learners\"\n",
        "\n",
        "            cluster_profiles.append(profile)\n",
        "\n",
        "        return pd.DataFrame(cluster_profiles)\n",
        "\n",
        "    def plot_cluster_profiles(self, cluster_profile_df):\n",
        "        \"\"\"Visualize performance profiles\"\"\"\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        # Plot theory vs practical skills\n",
        "        for _, row in cluster_profile_df.iterrows():\n",
        "            plt.scatter(\n",
        "                row['theory_avg'],\n",
        "                row['practical_avg'],\n",
        "                s=row['size'] * 10,\n",
        "                label=f\"{row['profile_type']} (n={row['size']})\"\n",
        "            )\n",
        "\n",
        "        # Add reference lines\n",
        "        max_val = max(cluster_profile_df[['theory_avg', 'practical_avg']].max().max(), 100)\n",
        "        plt.plot([0, max_val], [0, max_val], 'k--', alpha=0.3)\n",
        "        plt.plot([50, max_val], [50, 50], 'r:', alpha=0.3)  # Passing threshold\n",
        "        plt.plot([50, 50], [50, max_val], 'r:', alpha=0.3)\n",
        "\n",
        "        plt.xlabel('Theory Skills (Avg Score)')\n",
        "        plt.ylabel('Practical Skills (Avg Score)')\n",
        "        plt.title('Student Performance Profiles')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig('performance_profiles.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    def plot_em_convergence(self, filename='em_convergence.png'):\n",
        "        \"\"\"Visualize EM algorithm convergence\"\"\"\n",
        "        if not self.log_likelihoods:\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        k_values = range(2, len(self.log_likelihoods) + 2)\n",
        "        plt.plot(k_values, self.log_likelihoods, 'go-')\n",
        "\n",
        "        # Mark optimal cluster count\n",
        "        optimal_idx = self.optimal_k - 2\n",
        "        plt.plot(self.optimal_k, self.log_likelihoods[optimal_idx], 'ro',\n",
        "                 markersize=8, label=f'Optimal k={self.optimal_k}')\n",
        "\n",
        "        plt.xlabel('Number of Clusters')\n",
        "        plt.ylabel('Log-Likelihood (ELBO)')\n",
        "        plt.title('EM Algorithm Convergence')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(filename, dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 4. PATHWAY OPTIMIZATION\n",
        "# =========================\n",
        "\n",
        "class PathwayGenerator:\n",
        "    \"\"\"\n",
        "    Creates personalized learning pathways based on:\n",
        "    - Performance clusters\n",
        "    - Vygotsky's Zone of Proximal Development (ZPD)\n",
        "    - Time constraints (T_max = 12 hrs/week)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, threshold=60, max_hours=12):  # Lowered threshold\n",
        "        self.threshold = threshold  # Performance threshold\n",
        "        self.max_hours = max_hours  # Weekly time constraint\n",
        "\n",
        "    def identify_weak_areas(self, scores):\n",
        "        \"\"\"Find courses where score < threshold\"\"\"\n",
        "        return [i for i, score in enumerate(scores) if score < self.threshold]\n",
        "\n",
        "    def calculate_zpd_level(self, current_score, cluster_mean):\n",
        "        \"\"\"\n",
        "        Compute resource difficulty level using Vygotsky's ZPD:\n",
        "        L_resource = S_current + 0.4 * (μ_cluster - S_current)\n",
        "        \"\"\"\n",
        "        # Handle cases where cluster mean isn't higher\n",
        "        if cluster_mean <= current_score:\n",
        "            # Provide minimum 5-point challenge\n",
        "            return min(100, current_score + 5)\n",
        "        else:\n",
        "            zpd = current_score + 0.4 * (cluster_mean - current_score)\n",
        "            # Ensure at least 5-point challenge\n",
        "            return max(current_score + 5, min(100, zpd))\n",
        "\n",
        "    def optimize_pathway(self, weak_areas, course_scores, cluster_means):\n",
        "        \"\"\"Optimized pathway using dynamic programming knapsack solution\"\"\"\n",
        "        if not weak_areas:\n",
        "            return []\n",
        "\n",
        "        # Calculate utility (performance gap) and weights (time)\n",
        "        #utility = [100 - course_scores[i] for i in weak_areas]\n",
        "        # Calculate utility as normalized gap\n",
        "        max_score = 100\n",
        "        utility = [(max_score - course_scores[i]) / max_score for i in weak_areas]\n",
        "        weights = [2] * len(weak_areas)  # 2 hours per resource\n",
        "        capacity = self.max_hours\n",
        "\n",
        "        # Initialize DP table\n",
        "        n = len(utility)\n",
        "        dp = [[0] * (capacity + 1) for _ in range(n + 1)]\n",
        "\n",
        "        # Build DP table\n",
        "        for i in range(1, n + 1):\n",
        "            for w in range(1, capacity + 1):\n",
        "                if weights[i - 1] <= w:\n",
        "                    dp[i][w] = max(dp[i - 1][w],\n",
        "                                   dp[i - 1][w - weights[i - 1]] + utility[i - 1])\n",
        "                else:\n",
        "                    dp[i][w] = dp[i - 1][w]\n",
        "\n",
        "        # Backtrack to find selected courses\n",
        "        selected = []\n",
        "        w = capacity\n",
        "        for i in range(n, 0, -1):\n",
        "            if dp[i][w] != dp[i - 1][w]:\n",
        "                selected.append(weak_areas[i - 1])\n",
        "                w -= weights[i - 1]\n",
        "\n",
        "        # Generate pathway with ZPD-level resources\n",
        "        pathway = []\n",
        "        for area in selected:\n",
        "            zpd_level = self.calculate_zpd_level(\n",
        "                course_scores[area],\n",
        "                cluster_means[area]\n",
        "            )\n",
        "            pathway.append({\n",
        "                'course_index': area,\n",
        "                'zpd_level': round(zpd_level, 1),\n",
        "                'study_hours': 2,\n",
        "                'resources': self.select_resources(zpd_level)\n",
        "            })\n",
        "\n",
        "        return pathway\n",
        "\n",
        "    def select_resources(self, zpd_level):\n",
        "        \"\"\"Match resources to difficulty level (simulated)\"\"\"\n",
        "        # In production: Query resource database with difficulty filter\n",
        "        difficulty_bracket = int(zpd_level // 10) * 10  # Group by 10-point brackets\n",
        "\n",
        "        return [\n",
        "            f\"Video Lecture (Level: {difficulty_bracket}-{difficulty_bracket + 9})\",\n",
        "            f\"Practice Problems (Level: {difficulty_bracket}-{difficulty_bracket + 9})\",\n",
        "            f\"Interactive Simulation (Level: {difficulty_bracket}-{difficulty_bracket + 9})\"\n",
        "        ]\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 5. BLOCKCHAIN INTEGRATION\n",
        "# =======================\n",
        "\n",
        "class BlockchainSimulator:\n",
        "    \"\"\"\n",
        "    Simulates Hyperledger Fabric functionality for:\n",
        "    - IPFS content addressing\n",
        "    - On-chain hash storage\n",
        "    - Academic record verification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.chain = []\n",
        "        self.records = {}\n",
        "\n",
        "    def store_pathway(self, student_id, pathway_data):\n",
        "        \"\"\"Store pathway hash on blockchain with timestamp\"\"\"\n",
        "        # Simulate IPFS storage\n",
        "        cid = self._ipfs_store(pathway_data)\n",
        "\n",
        "        # Create blockchain record\n",
        "        timestamp = datetime.now().isoformat()\n",
        "        record = {\n",
        "            'student_id': student_id,\n",
        "            'ipfs_cid': cid,\n",
        "            'timestamp': timestamp,\n",
        "            'tx_hash': hashlib.sha256(f\"{student_id}{timestamp}\".encode()).hexdigest()\n",
        "        }\n",
        "\n",
        "        # Add to chain\n",
        "        self.chain.append(record)\n",
        "        self.records[student_id] = record\n",
        "        return record\n",
        "\n",
        "    def _ipfs_store(self, data):\n",
        "        \"\"\"Simulate IPFS storage (returns content identifier)\"\"\"\n",
        "        json_data = json.dumps(data).encode()\n",
        "        return f\"Qm{hashlib.sha256(json_data).hexdigest()[:46]}\"\n",
        "\n",
        "    def verify_record(self, student_id):\n",
        "        \"\"\"Verify pathway integrity using blockchain records\"\"\"\n",
        "        return self.records.get(student_id)\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 6. VISUALIZATION TOOLS\n",
        "# ======================\n",
        "\n",
        "class ResultVisualizer:\n",
        "    \"\"\"Generates publication-quality visualizations of results\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_score_comparison(pre_scores, post_scores):\n",
        "        \"\"\"Visualize pre/post intervention score distribution\"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Kernel Density Estimation plots with bandwidth adjustment\n",
        "        sns.kdeplot(pre_scores, fill=True, label='Pre-Intervention',\n",
        "                    alpha=0.5, bw_adjust=0.5)  # Added bw_adjust for smoothing\n",
        "        sns.kdeplot(post_scores, fill=True, label='Post-Intervention',\n",
        "                    alpha=0.5, bw_adjust=0.5)  # Added bw_adjust for smoothing\n",
        "\n",
        "        # Set y-axis limits\n",
        "        plt.ylim(0, 0.035)  # Increased y-axis range\n",
        "\n",
        "        plt.title('Score Distribution Improvement', fontsize=16)\n",
        "        plt.xlabel('Scores', fontsize=14)\n",
        "        plt.ylabel('Density', fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.savefig('score_distribution_comparison.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_cluster_performance(cluster_data):\n",
        "        \"\"\"Visualize cluster-specific improvements\"\"\"\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        clusters = sorted(cluster_data['cluster'].unique())\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(clusters)))\n",
        "\n",
        "        for i, cluster in enumerate(clusters):\n",
        "            cluster_df = cluster_data[cluster_data['cluster'] == cluster]\n",
        "            plt.scatter(\n",
        "                cluster_df['pre_score'],\n",
        "                cluster_df['post_score'],\n",
        "                color=colors[i],\n",
        "                label=f'Cluster {cluster}: {cluster_df[\"profile_type\"].iloc[0]}',\n",
        "                alpha=0.7\n",
        "            )\n",
        "\n",
        "        # Add identity line\n",
        "        max_score = max(cluster_data[['pre_score', 'post_score']].max().max(), 100)\n",
        "        plt.plot([0, max_score], [0, max_score], 'k--', alpha=0.5)\n",
        "        plt.plot([50, max_score], [50, 50], 'r:', alpha=0.3)  # Passing threshold\n",
        "        plt.plot([50, 50], [50, max_score], 'r:', alpha=0.3)\n",
        "\n",
        "        plt.title('Pre-vs-Post Scores by Cluster', fontsize=16)\n",
        "        plt.xlabel('Pre-Intervention Scores', fontsize=14)\n",
        "        plt.ylabel('Post-Intervention Scores', fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True, linestyle='--', alpha=0.5)\n",
        "        plt.savefig('cluster_performance.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_cluster_validation(metrics):\n",
        "        \"\"\"Visualize cluster validation metrics\"\"\"\n",
        "        fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "        # Silhouette and Calinski-Harabasz\n",
        "        k_values = range(2, len(metrics) + 2)\n",
        "        sil_scores = [m['silhouette'] for m in metrics]\n",
        "        cal_scores = [m['calinski_harabasz'] for m in metrics]\n",
        "\n",
        "        ax1.plot(k_values, sil_scores, 'b-o', label='Silhouette Score')\n",
        "        ax1.set_xlabel('Number of Clusters')\n",
        "        ax1.set_ylabel('Silhouette Score', color='b')\n",
        "        ax1.tick_params('y', colors='b')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        ax2 = ax1.twinx()\n",
        "        ax2.plot(k_values, cal_scores, 'r--o', label='Calinski-Harabasz Index')\n",
        "        ax2.set_ylabel('Calinski-Harabasz Index', color='r')\n",
        "        ax2.tick_params('y', colors='r')\n",
        "        fig.tight_layout()\n",
        "        plt.savefig('cluster_validation.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_performance_metrics(score_matrix, post_scores, pathways, courses, cluster_profiles):\n",
        "        \"\"\"\n",
        "        Compute comprehensive performance metrics:\n",
        "        1. Learning gain by cluster\n",
        "        2. Weak area remediation rate\n",
        "        3. Pathway efficiency\n",
        "        4. Resource utilization\n",
        "        5. Equity impact\n",
        "        6. Improvement list\n",
        "        \"\"\"\n",
        "        metrics = {}\n",
        "        improvements = []  # NEW: Store individual improvements\n",
        "\n",
        "        # 1. Overall learning gain\n",
        "        all_pre = score_matrix[courses].values.flatten()\n",
        "        all_post = post_scores[courses].values.flatten()\n",
        "        metrics['overall_improvement'] = np.mean(all_post - all_pre)\n",
        "\n",
        "        # 2. Cluster-specific gains\n",
        "        cluster_improvements = {}\n",
        "        for cluster_id in cluster_profiles['cluster']:\n",
        "            cluster_students = score_matrix[score_matrix['cluster'] == cluster_id].index\n",
        "            pre_avg = score_matrix.loc[cluster_students, courses].mean().mean()\n",
        "            post_avg = post_scores.loc[cluster_students, courses].mean().mean()\n",
        "            cluster_improvements[cluster_id] = {\n",
        "                'improvement': post_avg - pre_avg,\n",
        "                'size': len(cluster_students)\n",
        "            }\n",
        "        metrics['cluster_improvements'] = cluster_improvements\n",
        "\n",
        "        # 3. Weak area remediation\n",
        "        resolved_weak_areas = 0\n",
        "        total_weak_areas = 0\n",
        "\n",
        "        # NEW: Calculate individual student improvements\n",
        "        for student in score_matrix.index:\n",
        "            pre_avg = score_matrix.loc[student, courses].mean()\n",
        "            post_avg = post_scores.loc[student, courses].mean()\n",
        "            student_improvement = post_avg - pre_avg\n",
        "            improvements.append(student_improvement)\n",
        "\n",
        "            # Weak area analysis\n",
        "            weak_areas = [i for i, score in enumerate(score_matrix.loc[student, courses]) if score < 60]\n",
        "            total_weak_areas += len(weak_areas)\n",
        "\n",
        "            if student in pathways and pathways[student]:\n",
        "                for item in pathways[student]:\n",
        "                    course_idx = item['course_index']\n",
        "                    if post_scores.loc[student, courses[course_idx]] >= 60:\n",
        "                        resolved_weak_areas += 1\n",
        "\n",
        "        metrics['improvements'] = improvements  # NEW: Store for equity plot\n",
        "        metrics['weak_area_resolution'] = resolved_weak_areas / total_weak_areas if total_weak_areas > 0 else 0\n",
        "\n",
        "        # 4. Pathway efficiency\n",
        "        study_hours = []\n",
        "        for pathway in pathways.values():\n",
        "            if pathway:\n",
        "                study_hours.append(sum(item['study_hours'] for item in pathway))\n",
        "        metrics['avg_study_hours'] = np.mean(study_hours) if study_hours else 0\n",
        "\n",
        "        # 5. Equity impact (Gini coefficient of improvement)\n",
        "        sorted_improvements = np.sort(improvements)\n",
        "        n = len(sorted_improvements)\n",
        "        index = np.arange(1, n + 1)\n",
        "        gini = (np.sum((2 * index - n - 1) * sorted_improvements)) / (n * np.sum(sorted_improvements))\n",
        "        metrics['gini_improvement'] = gini\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_improvement_by_cluster(metrics, filename='cluster_improvements.png'):\n",
        "        \"\"\"Visualize improvement by cluster profile\"\"\"\n",
        "        cluster_data = []\n",
        "        for cluster_id, data in metrics['cluster_improvements'].items():\n",
        "            cluster_data.append({\n",
        "                'cluster': cluster_id,\n",
        "                'improvement': data['improvement'],\n",
        "                'size': data['size']\n",
        "            })\n",
        "        cluster_df = pd.DataFrame(cluster_data)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        ax = sns.barplot(x='cluster', y='improvement', data=cluster_df,\n",
        "                         palette='viridis', hue='size', dodge=False)\n",
        "\n",
        "        # Add size annotations\n",
        "        for i, row in enumerate(cluster_df.itertuples()):\n",
        "            ax.text(i, row.improvement + 0.2, f\"n={row.size}\",\n",
        "                    ha='center', fontsize=10)\n",
        "\n",
        "        plt.title('Average Score Improvement by Cluster', fontsize=16)\n",
        "        plt.xlabel('Cluster', fontsize=14)\n",
        "        plt.ylabel('Score Improvement', fontsize=14)\n",
        "        plt.grid(axis='y', alpha=0.3)\n",
        "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_equity_impact(improvements, filename='equity_impact.png'):\n",
        "        \"\"\"Visualize improvement distribution using Lorenz curve\"\"\"\n",
        "        sorted_improvements = np.sort(improvements)\n",
        "        cumulative = np.cumsum(sorted_improvements)\n",
        "        cumulative = cumulative / cumulative[-1] if cumulative[-1] != 0 else cumulative\n",
        "\n",
        "        perfect = np.linspace(0, 1, len(improvements))\n",
        "\n",
        "        # Calculate Gini coefficient\n",
        "        n = len(sorted_improvements)\n",
        "        index = np.arange(1, n + 1)\n",
        "        gini = (np.sum((2 * index - n - 1) * sorted_improvements)) / (n * np.sum(sorted_improvements))\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(perfect, cumulative, label='Actual Improvement')\n",
        "        plt.plot(perfect, perfect, 'k--', label='Perfect Equality')\n",
        "\n",
        "        # Fill area between curves\n",
        "        plt.fill_between(perfect, perfect, cumulative, alpha=0.1)\n",
        "\n",
        "        # Add Gini annotation\n",
        "        plt.annotate(f'Gini: {gini:.3f}', xy=(0.6, 0.3), fontsize=12,\n",
        "                     bbox=dict(boxstyle='round,pad=0.3', fc='white', alpha=0.8))\n",
        "\n",
        "        plt.title('Equity of Learning Improvements', fontsize=16)\n",
        "        plt.xlabel('Percentage of Students', fontsize=14)\n",
        "        plt.ylabel('Cumulative Improvement Share', fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.savefig(filename, dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_radar_chart(comparison_df, filename=\"radar_chart.png\"):\n",
        "        \"\"\"Create radar chart visualization of model metrics\"\"\"\n",
        "        import matplotlib.pyplot as plt\n",
        "        from math import pi\n",
        "\n",
        "        # Prepare data\n",
        "        models = comparison_df[\"Model\"].values\n",
        "        metrics = [\"Coherence\", \"Distinctiveness\", \"Relevance\"]\n",
        "        values = comparison_df[metrics].values\n",
        "\n",
        "        # Normalize values to 0-1 scale\n",
        "        normalized = (values - values.min(axis=0)) / (values.max(axis=0) - values.min(axis=0) + 1e-8)\n",
        "\n",
        "        # Compute angles\n",
        "        N = len(metrics)\n",
        "        angles = [n / float(N) * 2 * pi for n in range(N)]\n",
        "        angles += angles[:1]\n",
        "\n",
        "        # Create plot\n",
        "        fig = plt.figure(figsize=(10, 10))\n",
        "        ax = fig.add_subplot(111, polar=True)\n",
        "        ax.set_theta_offset(pi / 2)\n",
        "        ax.set_theta_direction(-1)\n",
        "        plt.xticks(angles[:-1], metrics)\n",
        "\n",
        "        # Draw ylabels\n",
        "        ax.set_rlabel_position(0)\n",
        "        plt.yticks([0.25, 0.5, 0.75], [\"0.25\", \"0.5\", \"0.75\"], color=\"grey\", size=10)\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "        # Plot each model\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(models)))\n",
        "        for i, model in enumerate(models):\n",
        "            stats = normalized[i].tolist()\n",
        "            stats += stats[:1]  # Close the polygon\n",
        "            ax.plot(angles, stats, linewidth=2, linestyle='solid', label=model, color=colors[i])\n",
        "            ax.fill(angles, stats, alpha=0.1, color=colors[i])\n",
        "\n",
        "        plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "        plt.title(\"Topic Model Comparison\", size=16, y=1.1)\n",
        "        plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "# ========================\n",
        "# TOPIC MODELING CLASSES\n",
        "# ========================\n",
        "\n",
        "class LDAOnlyModel:\n",
        "    \"\"\"Wrapper for LDA-only topic modeling\"\"\"\n",
        "\n",
        "    def __init__(self, n_topics=5):\n",
        "        self.n_topics = n_topics\n",
        "        self.vectorizer = None\n",
        "        self.lda = None\n",
        "\n",
        "    def train(self, documents):\n",
        "        \"\"\"Train LDA model\"\"\"\n",
        "        academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section',\n",
        "                               'example', 'problem', 'solution', 'study', 'learn']\n",
        "        self.vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english',\n",
        "                                          ngram_range=(1, 2), max_features=1000)\n",
        "        self.vectorizer.stop_words_ = set(list(self.vectorizer.get_stop_words()) + academic_stop_words)\n",
        "        dtm = self.vectorizer.fit_transform(documents)\n",
        "        self.lda = LatentDirichletAllocation(n_components=self.n_topics, random_state=42)\n",
        "        self.lda.fit(dtm)\n",
        "\n",
        "    def get_dominant_topic(self, documents):\n",
        "        \"\"\"Get dominant topic for documents\"\"\"\n",
        "        if not self.lda:\n",
        "            self.train(documents)\n",
        "        dtm = self.vectorizer.transform(documents)\n",
        "        return np.argmax(self.lda.transform(dtm), axis=1)\n",
        "\n",
        "\n",
        "class BERTOnlyModel:\n",
        "    \"\"\"Wrapper for BERT-only topic modeling\"\"\"\n",
        "\n",
        "    def __init__(self, n_topics=5):\n",
        "        self.n_topics = n_topics\n",
        "        self.bert_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        self.kmeans = KMeans(n_clusters=n_topics, random_state=42)\n",
        "\n",
        "    def get_dominant_topic(self, documents):\n",
        "        \"\"\"Get dominant topic for documents\"\"\"\n",
        "        embeddings = self.bert_model.encode(documents)\n",
        "        return self.kmeans.fit_predict(embeddings)\n",
        "\n",
        "# =========================\n",
        "# 7. MAIN EXECUTION PIPELINE\n",
        "# =========================\n",
        "def generate_template_file():\n",
        "    \"\"\"Create assessment template CSV if it doesn't exist\"\"\"\n",
        "    if os.path.exists(TEMPLATES_FILENAME):\n",
        "        return\n",
        "\n",
        "    templates = {\n",
        "        \"course\": [\n",
        "            \"Calculus I\", \"Calculus I\", \"Calculus I\", \"Calculus I\",\n",
        "            \"Physics I\", \"Physics I\", \"Physics I\", \"Physics I\",\n",
        "            \"Programming Fundamentals\", \"Programming Fundamentals\", \"Programming Fundamentals\",\n",
        "            \"Programming Fundamentals\",\n",
        "            \"Engineering Drawing\", \"Engineering Drawing\", \"Engineering Drawing\", \"Engineering Drawing\",\n",
        "            \"Electrical Circuits\", \"Electrical Circuits\", \"Electrical Circuits\", \"Electrical Circuits\"\n",
        "        ],\n",
        "        \"template\": [\n",
        "            \"Differential calculus problems involving {}\",\n",
        "            \"Integral calculus applications in {}\",\n",
        "            \"Limits and continuity exercises on {}\",\n",
        "            \"Derivative applications for {} problems\",\n",
        "            \"Kinematics problems in {} dimensions\",\n",
        "            \"Dynamics of systems with {} interactions\",\n",
        "            \"Thermodynamics applications for {} systems\",\n",
        "            \"Electromagnetism principles in {} contexts\",\n",
        "            \"Algorithms implementation using {} approach\",\n",
        "            \"Data structures exercises with {} applications\",\n",
        "            \"Object-oriented programming concepts for {}\",\n",
        "            \"Problem-solving techniques with {} paradigm\",\n",
        "            \"Orthographic projection of {} objects\",\n",
        "            \"Isometric drawing techniques for {} structures\",\n",
        "            \"CAD modeling exercises for {} components\",\n",
        "            \"Dimensioning standards applied to {} designs\",\n",
        "            \"Analysis of {} circuits using Kirchhoff's laws\",\n",
        "            \"AC circuit behavior with {} components\",\n",
        "            \"Transient response in {} networks\",\n",
        "            \"Power distribution systems for {} applications\"\n",
        "        ],\n",
        "        \"topic\": [\n",
        "            \"polynomial functions\", \"trigonometric functions\", \"exponential growth\", \"optimization\",\n",
        "            \"mechanical systems\", \"fluid dynamics\", \"electromagnetic fields\", \"thermal systems\",\n",
        "            \"sorting algorithms\", \"tree structures\", \"inheritance patterns\", \"recursive solutions\",\n",
        "            \"mechanical parts\", \"architectural elements\", \"piping systems\", \"electrical components\",\n",
        "            \"resistive networks\", \"capacitive circuits\", \"inductive loads\", \"filter designs\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    pd.DataFrame(templates).to_csv(TEMPLATES_FILENAME, index=False)\n",
        "    print(f\"Created assessment template file: {TEMPLATES_FILENAME}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if IN_COLAB:\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "        # Download NLTK punkt_tab resource\n",
        "        nltk.download('punkt_tab')\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"SANKOFA PATHWAYS: Personalized Learning System\")\n",
        "    print(\"Soroti University Implementation (Google Colab)\" if IN_COLAB else \"Local Execution\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Define courses\n",
        "    courses = [\n",
        "        \"Calculus I\", \"Physics I\", \"Programming Fundamentals\",\n",
        "        \"Engineering Drawing\", \"Electrical Circuits\"\n",
        "    ]\n",
        "\n",
        "    # Generate template file if needed\n",
        "    generate_template_file()\n",
        "\n",
        "    # --------------------\n",
        "    # 1. Generate or load mock data\n",
        "    # --------------------\n",
        "    if os.path.exists(DATASET_FILENAME):\n",
        "        print(f\"\\n[1/6] Loading dataset from {DATASET_FILENAME}...\")\n",
        "        raw_df = pd.read_csv(DATASET_FILENAME)\n",
        "    else:\n",
        "        print(\"\\n[1/6] Generating synthetic dataset...\")\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Load assessment templates\n",
        "        templates_df = pd.read_csv(TEMPLATES_FILENAME)\n",
        "        print(f\"Loaded assessment templates from {TEMPLATES_FILENAME}\")\n",
        "\n",
        "        # Create 100 student records with multiple assessments\n",
        "        student_ids = [f\"STU{1000 + i}\" for i in range(100)]\n",
        "        data = []\n",
        "        assessment_types = ['Test 1', 'Test 2', 'Coursework 1', 'Coursework 2', 'Final Exam']\n",
        "\n",
        "        # Create distinct student groups\n",
        "        for i, student in enumerate(student_ids):\n",
        "            # Create 3 distinct performance groups\n",
        "            if i < 30:  # Low performers\n",
        "                base_score = np.random.normal(45, 8)\n",
        "            elif i < 70:  # Medium performers\n",
        "                base_score = np.random.normal(65, 10)\n",
        "            else:  # High performers\n",
        "                base_score = np.random.normal(80, 6)\n",
        "\n",
        "            for course in courses:\n",
        "                # Get templates for this course\n",
        "                course_templates = templates_df[templates_df['course'] == course]\n",
        "\n",
        "                # Generate 5 assessments per course\n",
        "                for assessment_idx, assessment_name in enumerate(assessment_types):\n",
        "                    # Add course-specific variations\n",
        "                    course_adjustment = np.random.uniform(-5, 5)\n",
        "\n",
        "                    # Assessment-specific variation\n",
        "                    if assessment_name == 'Final Exam':\n",
        "                        assessment_adjust = np.random.uniform(-3, 3)\n",
        "                    else:\n",
        "                        assessment_adjust = np.random.uniform(-8, 8)\n",
        "\n",
        "                    score = base_score + course_adjustment + assessment_adjust\n",
        "                    score = max(0, min(100, score))\n",
        "\n",
        "                    # Select random template and topic\n",
        "                    template_row = course_templates.sample(1).iloc[0]\n",
        "                    template = template_row['template']\n",
        "                    topic = template_row['topic']\n",
        "                    assessment_text = f\"{assessment_name}: \" + template.format(topic)\n",
        "\n",
        "                    data.append({\n",
        "                        'student_id': student,\n",
        "                        'course': course,\n",
        "                        'score': score,\n",
        "                        'assessment_text': assessment_text,\n",
        "                        'assessment_type': assessment_name,\n",
        "                        'assessment_idx': assessment_idx\n",
        "                    })\n",
        "\n",
        "        raw_df = pd.DataFrame(data)\n",
        "        raw_df.to_csv(DATASET_FILENAME, index=False)\n",
        "        print(f\"Saved dataset to {DATASET_FILENAME}\")\n",
        "\n",
        "    # -------------------\n",
        "    # 2. Preprocess data\n",
        "    # -------------------\n",
        "    print(\"[2/6] Preprocessing data with differential privacy...\")\n",
        "    preprocessor = DataPreprocessor(epsilon=0.85)\n",
        "    processed_df = preprocessor.preprocess(raw_df)\n",
        "\n",
        "    # Pivot to student-course matrix\n",
        "    score_matrix = processed_df.pivot_table(\n",
        "        index='hashed_id',\n",
        "        columns='course',\n",
        "        values='score',\n",
        "        aggfunc='mean'\n",
        "    ).fillna(65)  # Fill missing with mean\n",
        "\n",
        "    # Ensure no missing values remain\n",
        "    score_matrix = score_matrix.fillna(score_matrix.median())\n",
        "\n",
        "    # ---------------------------\n",
        "    # 3. Hybrid topic modeling\n",
        "    # ---------------------------\n",
        "    print(\"[3/6] Performing advanced hybrid topic modeling...\")\n",
        "    documents = processed_df['assessment_text'].unique()\n",
        "\n",
        "    # Create all models for comprehensive comparison\n",
        "    models_to_compare = {\n",
        "        \"LDA Only\": LDAOnlyModel(n_topics=5),\n",
        "        \"BERT Only\": BERTOnlyModel(n_topics=5),\n",
        "        \"Original Hybrid\": HybridTopicModel(lambda_weight=0.85, n_topics=5),\n",
        "        \"Enhanced Hybrid\": EnhancedHybridTopicModel(\n",
        "            lambda_weight=0.85,  # More weight to BERT semantics\n",
        "            n_topics=7,  # Slightly more topics\n",
        "            fine_tune_steps=200  # More fine-tuning\n",
        "        )\n",
        "    }\n",
        "\n",
        "    # Train models\n",
        "    print(\"Training models for comparison...\")\n",
        "    for name, model in models_to_compare.items():\n",
        "        if name == \"LDA Only\" or name == \"BERT Only\":\n",
        "            continue  # Will be handled in evaluation\n",
        "\n",
        "        print(f\"- Training {name}...\")\n",
        "        if FINE_TUNE_BERT and IN_COLAB:\n",
        "            model.fine_tune_bert(documents)\n",
        "\n",
        "        if name == \"Original Hybrid\":\n",
        "            model.train_lda(documents)\n",
        "            # Ensure topic embeddings are computed\n",
        "            if not hasattr(model, 'topic_embeddings') or model.topic_embeddings is None:\n",
        "                model.compute_topic_embeddings(documents)\n",
        "        elif name == \"Enhanced Hybrid\":\n",
        "            # This handles all training internally\n",
        "            model.compute_topic_embeddings(documents)\n",
        "\n",
        "    # Evaluate and compare all models\n",
        "    if not PRODUCTION_MODE:\n",
        "        print(\"\\n[3.5/6] Comprehensive model evaluation...\")\n",
        "        evaluator = TopicModelEvaluator(\n",
        "            documents=processed_df['assessment_text'].tolist(),\n",
        "            n_topics=5\n",
        "        )\n",
        "\n",
        "        # Perform comprehensive evaluation\n",
        "        comparison_df, report = evaluator.comprehensive_evaluation(models_to_compare)\n",
        "\n",
        "        # Print and save report\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"MODEL COMPARISON RESULTS:\")\n",
        "        print(\"=\" * 70)\n",
        "        print(report)\n",
        "\n",
        "        # Save detailed report\n",
        "        with open(\"model_comparison_report.txt\", \"w\") as f:\n",
        "            f.write(report)\n",
        "\n",
        "        print(\"\\nVisualizations saved:\")\n",
        "        print(\"- model_metrics_comparison.png\")\n",
        "        print(\"- radar_chart.png\")\n",
        "        print(\"- topic_quality_scatter.png\")\n",
        "        print(\"- model_comparison_report.txt\")\n",
        "\n",
        "        # Use the best model for the rest of the pipeline\n",
        "        best_model_name = comparison_df.iloc[0][\"Model\"]\n",
        "        print(f\"\\nSelected best model for the pipeline: {best_model_name}\")\n",
        "        topic_model = models_to_compare[best_model_name]\n",
        "    else:\n",
        "        # In production, default to enhanced hybrid\n",
        "        topic_model = models_to_compare[\"Enhanced Hybrid\"]\n",
        "        print(\"Using Enhanced Hybrid model in production mode\")\n",
        "\n",
        "    # Continue with the selected model\n",
        "    print(\"Computing document-topic distributions...\")\n",
        "    processed_df['dominant_topic'] = topic_model.get_dominant_topic(\n",
        "        processed_df['assessment_text'].tolist()\n",
        "    )\n",
        "\n",
        "    # Create topic distribution per student\n",
        "    topic_dist = pd.crosstab(\n",
        "        index=processed_df['hashed_id'],\n",
        "        columns=processed_df['dominant_topic'],\n",
        "        normalize='index'\n",
        "    ).add_prefix('topic_')\n",
        "\n",
        "    # -------------------------\n",
        "    # 4. Student clustering\n",
        "    # -------------------------\n",
        "    print(\"[4/6] Clustering students...\")\n",
        "\n",
        "    # Initialize visualizer\n",
        "    visualizer = ResultVisualizer()\n",
        "\n",
        "    # Prepare feature matrix: scores + topic distribution\n",
        "    feature_matrix = pd.concat([score_matrix, topic_dist], axis=1)\n",
        "\n",
        "    # Feature engineering - create all necessary columns\n",
        "    feature_matrix['theory_avg'] = feature_matrix[['Calculus I', 'Physics I']].mean(axis=1)\n",
        "    feature_matrix['practical_avg'] = feature_matrix[\n",
        "        ['Programming Fundamentals', 'Engineering Drawing', 'Electrical Circuits']].mean(axis=1)\n",
        "    feature_matrix['overall_performance'] = feature_matrix[courses].mean(axis=1)\n",
        "    feature_matrix['variance'] = feature_matrix[courses].var(axis=1)\n",
        "    feature_matrix['theory_practical_gap'] = abs(feature_matrix['theory_avg'] - feature_matrix['practical_avg'])\n",
        "    feature_matrix['max_score'] = feature_matrix[courses].max(axis=1)\n",
        "    feature_matrix['min_score'] = feature_matrix[courses].min(axis=1)\n",
        "    feature_matrix['max_min_gap'] = feature_matrix['max_score'] - feature_matrix['min_score']\n",
        "    feature_matrix['weak_subject_count'] = (feature_matrix[courses] < 60).sum(axis=1)\n",
        "    feature_matrix['strong_subject_count'] = (feature_matrix[courses] > 80).sum(axis=1)\n",
        "\n",
        "    # Additional features\n",
        "    feature_matrix['theory_ratio'] = feature_matrix['theory_avg'] / feature_matrix['overall_performance']\n",
        "    feature_matrix['practical_ratio'] = feature_matrix['practical_avg'] / feature_matrix['overall_performance']\n",
        "    feature_matrix['imbalance_score'] = abs(feature_matrix['theory_ratio'] - 0.5)\n",
        "    feature_matrix['weakness_factor'] = feature_matrix['weak_subject_count'] / len(courses)\n",
        "\n",
        "    # Remove non-numeric columns for clustering\n",
        "    clustering_features = feature_matrix.select_dtypes(include=[np.number])\n",
        "\n",
        "    # Ensure proper alignment and no missing values\n",
        "    clustering_features = clustering_features.dropna()\n",
        "\n",
        "    # Create enhanced clusterer\n",
        "    clusterer = EnhancedStudentClusterer(max_clusters=8)\n",
        "    optimal_k, silhouette_scores = clusterer.optimize_cluster_count(clustering_features)\n",
        "    print(f\"Optimal cluster count: {optimal_k} (Silhouette optimized)\")\n",
        "\n",
        "    # Fit GMM and assign clusters\n",
        "    cluster_labels = clusterer.fit_gmm(clustering_features)\n",
        "    score_matrix['cluster'] = cluster_labels\n",
        "    feature_matrix['cluster'] = cluster_labels\n",
        "\n",
        "    # Interpret clusters and add profiles\n",
        "    cluster_profiles = clusterer.interpret_clusters(feature_matrix)\n",
        "    profile_mapping = cluster_profiles.set_index('cluster')['profile_type'].to_dict()\n",
        "    feature_matrix['profile_type'] = feature_matrix['cluster'].map(profile_mapping)\n",
        "    score_matrix['profile_type'] = feature_matrix['profile_type']\n",
        "\n",
        "    # Print cluster statistics\n",
        "    print(\"\\nCluster Statistics:\")\n",
        "    print(feature_matrix.groupby('cluster').agg({\n",
        "        'overall_performance': ['mean', 'std'],\n",
        "        'theory_avg': 'mean',\n",
        "        'practical_avg': 'mean',\n",
        "        'variance': 'mean',\n",
        "        'weak_subject_count': 'mean'\n",
        "    }))\n",
        "\n",
        "    # Print cluster validation metrics\n",
        "    print(\"\\nCluster Validation Metrics:\")\n",
        "    if optimal_k >= 2 and len(clusterer.cluster_metrics) >= optimal_k - 1:\n",
        "        metrics_index = optimal_k - 2\n",
        "        print(f\"Silhouette Score: {clusterer.cluster_metrics[metrics_index]['silhouette']:.3f}\")\n",
        "        print(f\"Calinski-Harabasz: {clusterer.cluster_metrics[metrics_index]['calinski_harabasz']:.1f}\")\n",
        "        print(f\"Davies-Bouldin: {clusterer.cluster_metrics[metrics_index]['davies_bouldin']:.3f}\")\n",
        "\n",
        "    # Visualize clusters\n",
        "    clusterer.plot_cluster_profiles(cluster_profiles)\n",
        "    if clusterer.cluster_metrics:\n",
        "        visualizer.plot_cluster_validation(clusterer.cluster_metrics)\n",
        "\n",
        "    # ------------------------\n",
        "    # 5. Pathway generation\n",
        "    # ------------------------\n",
        "    print(\"[5/6] Generating personalized pathways...\")\n",
        "    pathway_gen = PathwayGenerator(threshold=60, max_hours=12)\n",
        "    blockchain = BlockchainSimulator()\n",
        "\n",
        "    pathways = {}\n",
        "    students_with_pathways = 0\n",
        "\n",
        "    # Create reverse ID mapping\n",
        "    reverse_mapping = {v: k for k, v in preprocessor.id_mapping.items()}\n",
        "\n",
        "    for student in tqdm(score_matrix.index, desc=\"Generating pathways\"):\n",
        "        student_scores = score_matrix.loc[student, courses].values\n",
        "        cluster_id = score_matrix.loc[student, 'cluster']\n",
        "\n",
        "        # Use cluster mean from feature matrix\n",
        "        cluster_mean = feature_matrix[feature_matrix['cluster'] == cluster_id][courses].mean().values\n",
        "\n",
        "        weak_areas = pathway_gen.identify_weak_areas(student_scores)\n",
        "        pathway = pathway_gen.optimize_pathway(\n",
        "            weak_areas, student_scores, cluster_mean\n",
        "        )\n",
        "\n",
        "        if pathway:  # Only store if pathway is not empty\n",
        "            blockchain.store_pathway(student, pathway)\n",
        "            pathways[student] = pathway\n",
        "            students_with_pathways += 1\n",
        "\n",
        "    # Save all pathways to CSV\n",
        "    pathway_output = []\n",
        "    for hashed_id, pathway in pathways.items():\n",
        "        original_id = reverse_mapping.get(hashed_id, hashed_id)\n",
        "        for item in pathway:\n",
        "            course_name = courses[item['course_index']]\n",
        "            pathway_output.append({\n",
        "                'student_id': original_id,\n",
        "                'hashed_id': hashed_id,\n",
        "                'cluster': score_matrix.loc[hashed_id, 'cluster'],\n",
        "                'profile_type': score_matrix.loc[hashed_id, 'profile_type'],\n",
        "                'course': course_name,\n",
        "                'current_score': score_matrix.loc[hashed_id, course_name],\n",
        "                'zpd_level': item['zpd_level'],\n",
        "                'study_hours': item['study_hours'],\n",
        "                'resources': \", \".join(item['resources'])\n",
        "            })\n",
        "\n",
        "    pathway_df = pd.DataFrame(pathway_output)\n",
        "    pathway_df.to_csv(\"all_student_pathways.csv\", index=False)\n",
        "    print(f\"Saved all pathways to all_student_pathways.csv\")\n",
        "\n",
        "    # --------------------\n",
        "    # 6. Simulate results\n",
        "    # --------------------\n",
        "    print(\"[6/6] Simulating intervention and visualizing results...\")\n",
        "\n",
        "    # Simulate post-intervention scores with cluster-based improvements\n",
        "    post_scores = score_matrix.copy()\n",
        "    improvement_factors = {\n",
        "        \"Low Performers\": 0.40, #was 0.3, then o.35 now increased to 0.40\n",
        "        \"Inconsistent Learners\": 0.35, #was 0.25, then 0.30, now 0.35\n",
        "        \"Balanced Learners\": 0.22, #was 0.2\n",
        "        \"Theory-Focused\": 0.25, #was 0.22\n",
        "        \"Practice-Focused\": 0.28, #was 0.22\n",
        "        \"High Performers\": 0.12 #was 0.15\n",
        "    }\n",
        "\n",
        "    # More realistic improvement calculation\n",
        "    for student in score_matrix.index:\n",
        "        profile_type = score_matrix.loc[student, 'profile_type']\n",
        "        improvement = improvement_factors.get(profile_type, 0.2)\n",
        "\n",
        "        for course in courses:\n",
        "            current_score = score_matrix.loc[student, course]\n",
        "            if current_score < 60:  # Focused improvement for weak areas\n",
        "                post_scores.loc[student, course] = min(100, current_score + (100 - current_score) * improvement)\n",
        "            else:\n",
        "                # Smaller improvement for already strong areas\n",
        "                post_scores.loc[student, course] = min(100, current_score * (1 + improvement / 3))\n",
        "\n",
        "    for course in courses:\n",
        "        for cluster_type in improvement_factors:\n",
        "            cluster_mask = score_matrix['profile_type'] == cluster_type\n",
        "            current_scores = score_matrix.loc[cluster_mask, course]\n",
        "            improvement = improvement_factors[cluster_type]\n",
        "            post_scores.loc[cluster_mask, course] = np.minimum(\n",
        "                current_scores + (100 - current_scores) * improvement,\n",
        "                100\n",
        "            )\n",
        "\n",
        "    # Visualization\n",
        "    visualizer = ResultVisualizer()\n",
        "\n",
        "    # Flatten scores for distribution plot\n",
        "    all_pre_scores = score_matrix[courses].values.flatten()\n",
        "    all_post_scores = post_scores[courses].values.flatten()\n",
        "    visualizer.plot_score_comparison(all_pre_scores, all_post_scores)\n",
        "\n",
        "    # Prepare cluster performance data\n",
        "    cluster_perf = score_matrix[['cluster', 'profile_type']].copy()\n",
        "    cluster_perf['pre_score'] = score_matrix[courses].mean(axis=1)\n",
        "    cluster_perf['post_score'] = post_scores[courses].mean(axis=1)\n",
        "    visualizer.plot_cluster_performance(cluster_perf.reset_index())\n",
        "\n",
        "    # NEW: Calculate comprehensive metrics\n",
        "    metrics = visualizer.calculate_performance_metrics(\n",
        "        score_matrix,\n",
        "        post_scores,\n",
        "        pathways,\n",
        "        courses,\n",
        "        cluster_profiles\n",
        "    )\n",
        "\n",
        "    # NEW: Visualize cluster improvements\n",
        "    visualizer.plot_improvement_by_cluster(metrics)\n",
        "\n",
        "    # NEW: Plot equity impact\n",
        "    visualizer.plot_equity_impact(metrics['improvements'])\n",
        "    print(\"Saved equity_impact.png\")\n",
        "\n",
        "    # ------------------\n",
        "    # 7. Output results\n",
        "    # ------------------\n",
        "    print(\"\\nRESULTS SUMMARY:\")\n",
        "    print(f\"- Students clustered into {optimal_k} performance groups\")\n",
        "    print(f\"- Average pre-intervention score: {np.mean(all_pre_scores):.1f}\")\n",
        "    print(f\"- Average post-intervention score: {np.mean(all_post_scores):.1f}\")\n",
        "    print(f\"- Average improvement: {np.mean(all_post_scores - all_pre_scores):.1f} points\")\n",
        "    print(f\"- Personalized pathways generated for {students_with_pathways} students\")\n",
        "    print(f\"- Average improvement: {metrics['overall_improvement']:.1f} points\")\n",
        "    print(f\"- Weak area resolution rate: {metrics['weak_area_resolution'] * 100:.1f}%\")\n",
        "    print(f\"- Average weekly study time: {metrics['avg_study_hours']:.1f} hours\")\n",
        "    print(f\"- Improvement equity (Gini): {metrics['gini_improvement']:.3f} (lower=better)\")\n",
        "\n",
        "    print(\"\\nCluster-Specific Improvements:\")\n",
        "    for cluster_id, data in metrics['cluster_improvements'].items():\n",
        "        profile = cluster_profiles[cluster_profiles['cluster'] == cluster_id]['profile_type'].iloc[0]\n",
        "        print(f\"  - Cluster {cluster_id} ({profile}): +{data['improvement']:.1f} points (n={data['size']})\")\n",
        "\n",
        "    # Find a student with a pathway\n",
        "    sample_student = next((sid for sid, path in pathways.items() if path), None)\n",
        "\n",
        "    if sample_student:\n",
        "        # Get original ID for sample student\n",
        "        original_id = reverse_mapping.get(sample_student, \"Unknown\")\n",
        "        profile_type = score_matrix.loc[sample_student, 'profile_type']\n",
        "\n",
        "        print(f\"\\nSample pathway for student {original_id} ({profile_type}):\")\n",
        "        for item in pathways[sample_student]:\n",
        "            course_name = courses[item['course_index']]\n",
        "            current_score = score_matrix.loc[sample_student, course_name]\n",
        "            print(f\"  - Course: {course_name} (Current Score: {current_score:.1f})\")\n",
        "            print(f\"    ZPD Level: {item['zpd_level']:.1f}\")\n",
        "            print(f\"    Study Hours: {item['study_hours']}\")\n",
        "            print(f\"    Resources: {item['resources'][0]}\")\n",
        "\n",
        "    print(\"\\nVisualizations saved:\")\n",
        "    print(\"- bic_optimization.png: Cluster selection using BIC\")\n",
        "    print(\"- performance_profiles.png: Cluster performance profiles\")\n",
        "    print(\"- score_distribution_comparison.png: Pre/post score distributions\")\n",
        "    print(\"- cluster_performance.png: Improvement by cluster\")\n",
        "    print(\"- cluster_validation.png: Cluster quality metrics\")\n",
        "\n",
        "    print(\"\\nExecution complete. Results saved in Colab environment.\" if IN_COLAB else \"Execution complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5049b8ef8a04435994ad344e31527292",
            "0eba697a64144f3e8b6fde3e77b97cc4",
            "0660063e2b3b4e58b7ef40148b7024bd",
            "7f5535c2583f459fbe968238a668d82d",
            "55246e70760c45dabf936981730119bf",
            "b117c5c97408413e8b49f9a24a508e3d",
            "a7dcaf7709dd4d71bde9729d4d0af2e5",
            "4f41d6ffc35c4abb9ca45dadd27b935d",
            "9d073a4a478e40ae85e6c1d8cd4ae381",
            "6cbe72fe416240bfaeac315309e26b83",
            "55d130fa4f1b487cac8e977f8d8e70ff",
            "7246e836ecb9487884f38696f9286401",
            "5940b9163cff438b82cead16e2119b4c",
            "e8f3f6eef1f14161866dba37acd10064",
            "18978d11462c484ebf10424523140175",
            "7dcd472cee0a4ab9941277c39d8f37a1",
            "e6cf9ca1ea0044fe988bdf925ce1ebce",
            "a434b511a7994149be846a95b52abc5f",
            "a4c1d15269e2496f86ea13222b1c611b",
            "ef9567665c29497abc54bc861193bb2a",
            "f4b4492e947c4445b48c94870bbe9037",
            "26e6d5b1d60248dba229e6bf98070111"
          ]
        },
        "id": "RE0VVgxB9zKA",
        "outputId": "9b3eb8c0-954b-42b7-e991-b53f81855829"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gensim not installed. Topic coherence metrics disabled.\n",
            "============================================================\n",
            "SANKOFA PATHWAYS: Personalized Learning System\n",
            "Soroti University Implementation (Google Colab)\n",
            "============================================================\n",
            "\n",
            "[1/6] Loading dataset from soroti_engineering_dataset.csv...\n",
            "[2/6] Preprocessing data with differential privacy...\n",
            "[3/6] Performing advanced hybrid topic modeling...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: sentence-transformers/all-MiniLM-L6-v2\n",
            "Loading model: sentence-transformers/all-MiniLM-L6-v2\n",
            "Training models for comparison...\n",
            "- Training Original Hybrid...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5049b8ef8a04435994ad344e31527292"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26/26 00:22, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gensim not available. Using default LDA model.\n",
            "- Training Enhanced Hybrid...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7246e836ecb9487884f38696f9286401"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39/39 00:34, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HDBSCAN found 4 clusters\n",
            "Optimizing LDA topic count in range [2, 3, 4, 5, 6, 7]...\n",
            "  Topics=2 | Coherence=-1.361\n",
            "  Topics=3 | Coherence=-1.250\n",
            "  Topics=4 | Coherence=-1.290\n",
            "  Topics=5 | Coherence=-1.244\n",
            "  Topics=6 | Coherence=-1.076\n",
            "  Topics=7 | Coherence=-0.960\n",
            "Selected LDA model with 7 topics (Coherence=-0.960)\n",
            "\n",
            "[3.5/6] Comprehensive model evaluation...\n",
            "\n",
            "Evaluating LDA Only...\n",
            "Gensim not available. Using default LDA model.\n",
            "c_v coherence failed: name 'Dictionary' is not defined\n",
            "u_mass coherence failed: cannot access free variable 'dictionary' where it is not associated with a value in enclosing scope\n",
            "LDA Only Topics (Sample):\n",
            "  Topic 1: algorithms, using, sorting, using sorting, implementation using...\n",
            "  Topic 2: systems, components, coursework, test, exercises...\n",
            "  Topic 3: test, coursework, transient, transient response, loads...\n",
            "\n",
            "Evaluating BERT Only...\n",
            "c_v coherence failed: name 'Dictionary' is not defined\n",
            "u_mass coherence failed: cannot access free variable 'dictionary' where it is not associated with a value in enclosing scope\n",
            "BERT Only Topics (Sample):\n",
            "  Topic 1: algorithms, structures, solving, recursive, problem...\n",
            "  Topic 2: dynamics, optimization, derivative, systems, applications...\n",
            "  Topic 3: networks, circuits, systems, transient, loads...\n",
            "\n",
            "Evaluating Original Hybrid...\n",
            "c_v coherence failed: name 'Dictionary' is not defined\n",
            "u_mass coherence failed: cannot access free variable 'dictionary' where it is not associated with a value in enclosing scope\n",
            "Original Hybrid Topics (Sample):\n",
            "  Topic 1: problems, coursework, test, functions, calculus...\n",
            "  Topic 2: structures, exercises, algorithms, coursework, test...\n",
            "  Topic 3: systems, dynamics, test, coursework, networks...\n",
            "\n",
            "Evaluating Enhanced Hybrid...\n",
            "c_v coherence failed: name 'Dictionary' is not defined\n",
            "u_mass coherence failed: cannot access free variable 'dictionary' where it is not associated with a value in enclosing scope\n",
            "Enhanced Hybrid Topics (Sample):\n",
            "  Topic 1: problems involving, problems, differential calculus, polynomial, calculus...\n",
            "  Topic 2: exercises, structures, coursework, test, designs...\n",
            "  Topic 3: systems, cad, systems components, components, modeling...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-26-3059273481.py:1440: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=\"Model\", y=metric, data=comparison_df.sort_values(metric, ascending=False),\n",
            "/tmp/ipython-input-26-3059273481.py:1440: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=\"Model\", y=metric, data=comparison_df.sort_values(metric, ascending=False),\n",
            "/tmp/ipython-input-26-3059273481.py:1440: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=\"Model\", y=metric, data=comparison_df.sort_values(metric, ascending=False),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "MODEL COMPARISON RESULTS:\n",
            "======================================================================\n",
            "======================================================================\n",
            "TOPIC MODELING PERFORMANCE COMPARISON REPORT\n",
            "======================================================================\n",
            "Evaluated on 2500 documents\n",
            "Number of topics: 5\n",
            "----------------------------------------------------------------------\n",
            "Overall Ranking:\n",
            "4. Enhanced Hybrid: 1.355\n",
            "2. BERT Only: 1.341\n",
            "3. Original Hybrid: 1.004\n",
            "1. LDA Only: 0.967\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Detailed Metrics:\n",
            "Model                Coherence    Distinctiveness Relevance    Overall     \n",
            "Enhanced Hybrid      0.812        0.950           3.320        1.355       \n",
            "BERT Only            0.661        0.960           3.610        1.341       \n",
            "Original Hybrid      0.347        0.740           3.041        1.004       \n",
            "LDA Only             0.182        0.840           3.121        0.967       \n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Performance Insights:\n",
            "- Best performing model: Enhanced Hybrid\n",
            "- Coherence range: 0.182 - 0.812\n",
            "- Distinctiveness range: 0.740 - 0.960\n",
            "- Relevance range: 3.041 - 3.610\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Recommendations:\n",
            "- For coherence-focused applications: Use Enhanced Hybrid\n",
            "- For diverse topics: Use BERT Only\n",
            "- For relevant terms: Use BERT Only\n",
            "- Overall best model: Enhanced Hybrid\n",
            "======================================================================\n",
            "\n",
            "Visualizations saved:\n",
            "- model_metrics_comparison.png\n",
            "- radar_chart.png\n",
            "- topic_quality_scatter.png\n",
            "- model_comparison_report.txt\n",
            "\n",
            "Selected best model for the pipeline: Enhanced Hybrid\n",
            "Computing document-topic distributions...\n",
            "HDBSCAN membership_vector failed: 'HDBSCAN' object has no attribute 'membership_vector'\n",
            "One-hot encoding failed: 'HDBSCAN' object has no attribute 'predict'\n",
            "[4/6] Clustering students...\n",
            "Optimal cluster count: 2 (Silhouette optimized)\n",
            "\n",
            "Cluster Statistics:\n",
            "        overall_performance            theory_avg practical_avg  variance  \\\n",
            "                       mean        std       mean          mean      mean   \n",
            "cluster                                                                     \n",
            "0                  75.67212  10.042733  75.701103     75.652798  5.296202   \n",
            "1                  45.69272  11.166881  45.672833     45.705977  5.009342   \n",
            "\n",
            "        weak_subject_count  \n",
            "                      mean  \n",
            "cluster                     \n",
            "0                 0.090909  \n",
            "1                 4.755556  \n",
            "\n",
            "Cluster Validation Metrics:\n",
            "Silhouette Score: 0.542\n",
            "Calinski-Harabasz: 192.1\n",
            "Davies-Bouldin: 0.624\n",
            "[5/6] Generating personalized pathways...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating pathways: 100%|██████████| 100/100 [00:00<00:00, 259.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved all pathways to all_student_pathways.csv\n",
            "[6/6] Simulating intervention and visualizing results...\n",
            "Saved equity_impact.png\n",
            "\n",
            "RESULTS SUMMARY:\n",
            "- Students clustered into 2 performance groups\n",
            "- Average pre-intervention score: 62.2\n",
            "- Average post-intervention score: 73.5\n",
            "- Average improvement: 11.4 points\n",
            "- Personalized pathways generated for 49 students\n",
            "- Average improvement: 11.4 points\n",
            "- Weak area resolution rate: 82.2%\n",
            "- Average weekly study time: 8.9 hours\n",
            "- Improvement equity (Gini): 0.474 (lower=better)\n",
            "\n",
            "Cluster-Specific Improvements:\n",
            "  - Cluster 0 (High Performers): +2.9 points (n=55)\n",
            "  - Cluster 1 (Low Performers): +21.7 points (n=45)\n",
            "\n",
            "Sample pathway for student STU1015 (Low Performers):\n",
            "  - Course: Electrical Circuits (Current Score: 36.9)\n",
            "    ZPD Level: 41.9\n",
            "    Study Hours: 2\n",
            "    Resources: Video Lecture (Level: 40-49)\n",
            "  - Course: Engineering Drawing (Current Score: 35.5)\n",
            "    ZPD Level: 40.5\n",
            "    Study Hours: 2\n",
            "    Resources: Video Lecture (Level: 40-49)\n",
            "  - Course: Programming Fundamentals (Current Score: 34.5)\n",
            "    ZPD Level: 39.5\n",
            "    Study Hours: 2\n",
            "    Resources: Video Lecture (Level: 30-39)\n",
            "  - Course: Physics I (Current Score: 35.0)\n",
            "    ZPD Level: 40.0\n",
            "    Study Hours: 2\n",
            "    Resources: Video Lecture (Level: 30-39)\n",
            "  - Course: Calculus I (Current Score: 37.4)\n",
            "    ZPD Level: 42.4\n",
            "    Study Hours: 2\n",
            "    Resources: Video Lecture (Level: 40-49)\n",
            "\n",
            "Visualizations saved:\n",
            "- bic_optimization.png: Cluster selection using BIC\n",
            "- performance_profiles.png: Cluster performance profiles\n",
            "- score_distribution_comparison.png: Pre/post score distributions\n",
            "- cluster_performance.png: Improvement by cluster\n",
            "- cluster_validation.png: Cluster quality metrics\n",
            "\n",
            "Execution complete. Results saved in Colab environment.\n"
          ]
        }
      ]
    }
  ]
}