{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmO0QuDieMdQSaJTEoQwGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ogutiann/6COSC019C-Cyber-Security/blob/main/POTA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMD8m02IvvIm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from deap import algorithms, base, creator, tools\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import pygad\n",
        "import networkx as nx\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Configuration for large-scale deployment\n",
        "N_WORKERS = 5000\n",
        "N_TASKS = 10000\n",
        "CAPACITY = 3  # Max tasks per worker\n",
        "GPU_ACCELERATED = torch.cuda.is_available()\n",
        "\n",
        "if GPU_ACCELERATED:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"üöÄ Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"‚ö†Ô∏è Using CPU - GPU recommended for large-scale simulation\")\n",
        "\n",
        "######################\n",
        "### 1. System Model ##\n",
        "######################\n",
        "class Worker:\n",
        "    def __init__(self, id):\n",
        "        self.id = id\n",
        "        self.location = np.array([np.random.uniform(0,100), np.random.uniform(0,100)])\n",
        "        self.skill = np.array([np.random.uniform(2,5), np.random.uniform(2,5)])\n",
        "        self.speed = np.random.uniform(0.5, 2)\n",
        "        self.weights = np.random.dirichlet(np.ones(3))\n",
        "        self.reputation = np.random.uniform(0.7, 0.95)\n",
        "        self.utility_history = []\n",
        "        self.assigned_tasks = []\n",
        "\n",
        "    def travel_time(self, task_location):\n",
        "        distance = np.linalg.norm(self.location - task_location)\n",
        "        traffic_noise = np.random.laplace(0, 0.1)\n",
        "        return max(0.1, distance / self.speed + traffic_noise)\n",
        "\n",
        "class Task:\n",
        "    def __init__(self, id):\n",
        "        self.id = id\n",
        "        self.location = np.array([np.random.uniform(0,100), np.random.uniform(0,100)])\n",
        "        self.reward = np.random.uniform(5,20)\n",
        "        self.deadline = np.random.randint(10,60)\n",
        "        self.difficulty = np.random.uniform(1,10)\n",
        "        self.required_skill = np.array([np.random.uniform(1,4), np.random.uniform(1,4)])\n",
        "\n",
        "################################\n",
        "### 2. Deep-Quality Reputation ##\n",
        "################################\n",
        "class QualityVAE(nn.Module):\n",
        "    def __init__(self, input_dim=3, latent_dim=8):\n",
        "        super(QualityVAE, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.mu = nn.Linear(16, latent_dim)\n",
        "        self.logvar = nn.Linear(16, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = self.mu(h), self.logvar(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decoder(z), mu, logvar\n",
        "\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + 0.5 * KLD\n",
        "\n",
        "def compute_quality(features, vae_model):\n",
        "    with torch.no_grad():\n",
        "        recon, _, _ = vae_model(features)\n",
        "        error = torch.norm(features - recon, dim=1)\n",
        "    return 1 - error\n",
        "\n",
        "################################################\n",
        "### 3. Federated RL for Preference Optimization #\n",
        "################################################\n",
        "class LSTMPolicy(nn.Module):\n",
        "    def __init__(self, input_size=5, hidden_size=32, output_size=3):\n",
        "        super(LSTMPolicy, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.linear(x[:, -1, :])\n",
        "        return torch.softmax(x, dim=-1)\n",
        "\n",
        "def federated_average(models):\n",
        "    global_dict = {}\n",
        "    for key in models[0].state_dict().keys():\n",
        "        global_dict[key] = torch.stack([m.state_dict()[key] for m in models]).mean(0)\n",
        "    return global_dict\n",
        "\n",
        "def train_worker_rl(worker, tasks, epochs=20, batch_size=64):\n",
        "    model = LSTMPolicy().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Simulate historical data\n",
        "    n_samples = 1000\n",
        "    states = torch.randn(n_samples, 1, 5, device=device)  # [unmatched_ratio, rep, avg_util, travel_time, deadline_pressure]\n",
        "    actions = torch.randint(0, 3, (n_samples,), device=device)\n",
        "    rewards = torch.rand(n_samples, device=device)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        permutation = torch.randperm(n_samples)\n",
        "        for i in range(0, n_samples, batch_size):\n",
        "            indices = permutation[i:i+batch_size]\n",
        "            batch_states = states[indices]\n",
        "            batch_actions = actions[indices]\n",
        "            batch_rewards = rewards[indices]\n",
        "\n",
        "            # Forward pass\n",
        "            action_probs = model(batch_states)\n",
        "            selected_probs = action_probs[torch.arange(len(batch_actions)), batch_actions]\n",
        "\n",
        "            # Policy gradient loss\n",
        "            loss = -torch.log(selected_probs) * batch_rewards\n",
        "            loss = loss.mean()\n",
        "\n",
        "            # Optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model\n",
        "\n",
        "#############################################\n",
        "### 4. Matching Algorithms Implementations ##\n",
        "#############################################\n",
        "def worker_utility(worker, task):\n",
        "    tau = worker.travel_time(task.location)\n",
        "    skill_gap = np.mean(worker.skill - task.required_skill)\n",
        "    return (worker.weights[0] * (1/tau) +\n",
        "            worker.weights[1] * task.reward +\n",
        "            worker.weights[2] * skill_gap +\n",
        "            0.3 * worker.reputation)\n",
        "\n",
        "def task_utility(task, worker):\n",
        "    if np.any(worker.skill < task.required_skill):\n",
        "        return 0\n",
        "    tau = worker.travel_time(task.location)\n",
        "    return (0.7 * (1/tau) + 0.3 * worker.reputation)\n",
        "\n",
        "# 4.1 RAGS (Our Proposed)\n",
        "def rags_matching(workers, tasks, capacity=CAPACITY):\n",
        "    # Precompute utilities\n",
        "    w_utils = np.zeros((len(workers), len(tasks))\n",
        "    t_utils = np.zeros((len(tasks), len(workers)))\n",
        "\n",
        "    for i, worker in enumerate(workers):\n",
        "        for j, task in enumerate(tasks):\n",
        "            w_utils[i, j] = worker_utility(worker, task)\n",
        "            t_utils[j, i] = task_utility(task, worker)\n",
        "\n",
        "    # Preference lists\n",
        "    w_prefs = [np.argsort(-w_utils[i]) for i in range(len(workers))]\n",
        "    t_prefs = [np.argsort(-t_utils[j]) for j in range(len(tasks))]\n",
        "\n",
        "    # Initialize\n",
        "    proposals = np.zeros(len(workers), dtype=int)\n",
        "    worker_assignments = [[] for _ in range(len(workers))]\n",
        "    task_assignments = [[] for _ in range(len(tasks))]\n",
        "    unmatched = list(range(len(workers)))\n",
        "\n",
        "    # Matching loop\n",
        "    while unmatched:\n",
        "        i = unmatched.pop(0)\n",
        "        if proposals[i] >= len(tasks):\n",
        "            continue\n",
        "\n",
        "        j = w_prefs[i][proposals[i]]\n",
        "        proposals[i] += 1\n",
        "\n",
        "        if len(task_assignments[j]) < capacity:\n",
        "            worker_assignments[i].append(j)\n",
        "            task_assignments[j].append(i)\n",
        "        else:\n",
        "            # Find worst assigned worker\n",
        "            worst_idx = min(task_assignments[j], key=lambda x: t_utils[j, x])\n",
        "            if t_utils[j, i] > t_utils[j, worst_idx]:\n",
        "                # Replace worker\n",
        "                worker_assignments[worst_idx].remove(j)\n",
        "                task_assignments[j].remove(worst_idx)\n",
        "                unmatched.append(worst_idx)\n",
        "\n",
        "                worker_assignments[i].append(j)\n",
        "                task_assignments[j].append(i)\n",
        "            else:\n",
        "                unmatched.append(i)\n",
        "\n",
        "    return worker_assignments, task_assignments\n",
        "\n",
        "# 4.2 Classic Gale-Shapley\n",
        "def classic_gs(workers, tasks, capacity=CAPACITY):\n",
        "    # Static utilities\n",
        "    w_utils = np.zeros((len(workers), len(tasks))\n",
        "    t_utils = np.zeros((len(tasks), len(workers)))\n",
        "\n",
        "    for i, worker in enumerate(workers):\n",
        "        for j, task in enumerate(tasks):\n",
        "            w_utils[i, j] = worker_utility(worker, task)\n",
        "            t_utils[j, i] = task_utility(task, worker)\n",
        "\n",
        "    # Same as RAGS but without dynamic adjustments\n",
        "    return rags_matching(workers, tasks, capacity)\n",
        "\n",
        "# 4.3 Random Allocation\n",
        "def random_matching(workers, tasks, capacity=CAPACITY):\n",
        "    worker_assignments = [[] for _ in range(len(workers))]\n",
        "    task_assignments = [[] for _ in range(len(tasks))]\n",
        "\n",
        "    # Shuffle all possible assignments\n",
        "    all_pairs = [(i, j) for i in range(len(workers)) for j in range(len(tasks))]\n",
        "    random.shuffle(all_pairs)\n",
        "\n",
        "    for i, j in all_pairs:\n",
        "        if (len(worker_assignments[i]) < capacity and\n",
        "            len(task_assignments[j]) < capacity and\n",
        "            np.all(workers[i].skill >= tasks[j].required_skill)):\n",
        "            worker_assignments[i].append(j)\n",
        "            task_assignments[j].append(i)\n",
        "\n",
        "    return worker_assignments, task_assignments\n",
        "\n",
        "# 4.4 FML (Federated Matching without RL)\n",
        "def fml_matching(workers, tasks, capacity=CAPACITY):\n",
        "    # Average weights across workers\n",
        "    avg_weights = np.mean([w.weights for w in workers], axis=0)\n",
        "\n",
        "    # Override worker preferences with global average\n",
        "    for worker in workers:\n",
        "        worker.weights = avg_weights.copy()\n",
        "\n",
        "    return classic_gs(workers, tasks, capacity)\n",
        "\n",
        "# 4.5 SenseChain+ Simulation\n",
        "def sensechain_matching(workers, tasks, capacity=CAPACITY):\n",
        "    # Simulate blockchain overhead\n",
        "    time.sleep(0.001 * len(tasks))  # 1ms per task\n",
        "\n",
        "    # Same as classic GS\n",
        "    return classic_gs(workers, tasks, capacity)\n",
        "\n",
        "############################\n",
        "### 5. Evaluation Metrics ##\n",
        "############################\n",
        "def calculate_satisfaction(workers, tasks, assignments):\n",
        "    satisfaction = []\n",
        "    for i, worker in enumerate(workers):\n",
        "        utils = [worker_utility(worker, tasks[j]) for j in assignments[i]]\n",
        "        satisfaction.append(np.mean(utils) if utils else 0)\n",
        "    return np.mean(satisfaction)\n",
        "\n",
        "def calculate_task_coverage(task_assignments):\n",
        "    return sum(len(a) > 0 for a in task_assignments) / len(task_assignments)\n",
        "\n",
        "def calculate_quality(workers, tasks, assignments):\n",
        "    # Simulate data submissions with noise\n",
        "    qualities = []\n",
        "    for i, worker in enumerate(workers):\n",
        "        for task_id in assignments[i]:\n",
        "            task = tasks[task_id]\n",
        "            # Quality depends on worker skill and task difficulty\n",
        "            base_quality = np.mean(worker.skill - task.required_skill) / 5\n",
        "            noise = np.random.normal(0, 0.2 * (1 - worker.reputation))\n",
        "            qualities.append(max(0, min(1, base_quality + noise)))\n",
        "    return np.mean(qualities) if qualities else 0\n",
        "\n",
        "def check_stability(workers, tasks, worker_assignments, task_assignments):\n",
        "    blocking_pairs = 0\n",
        "    sample_size = min(1000, len(workers))\n",
        "\n",
        "    for i in np.random.choice(len(workers), sample_size, replace=False):\n",
        "        worker = workers[i]\n",
        "        current_utils = [worker_utility(worker, tasks[j]) for j in worker_assignments[i]]\n",
        "        current_min = min(current_utils) if current_utils else -np.inf\n",
        "\n",
        "        for j in np.random.choice(len(tasks), min(100, len(tasks)), replace=False):\n",
        "            if j in worker_assignments[i]:\n",
        "                continue\n",
        "\n",
        "            # Worker prefers this task\n",
        "            w_util = worker_utility(worker, tasks[j])\n",
        "            if w_util <= current_min:\n",
        "                continue\n",
        "\n",
        "            # Task prefers this worker\n",
        "            t_util = task_utility(tasks[j], worker)\n",
        "            current_workers = task_assignments[j]\n",
        "            if not current_workers:\n",
        "                blocking_pairs += 1\n",
        "                continue\n",
        "\n",
        "            min_current_util = min(task_utility(tasks[j], workers[k]) for k in current_workers)\n",
        "            if t_util > min_current_util:\n",
        "                blocking_pairs += 1\n",
        "\n",
        "    return 1 - (blocking_pairs / (sample_size * 100))\n",
        "\n",
        "##########################\n",
        "### 6. Ablation Models ###\n",
        "##########################\n",
        "def pota_no_rl(workers, tasks):\n",
        "    \"\"\"POTA without RL - use static weights\"\"\"\n",
        "    return rags_matching(workers, tasks)\n",
        "\n",
        "def pota_no_dqrs(workers, tasks):\n",
        "    \"\"\"POTA without DQRS - no reputation in utilities\"\"\"\n",
        "    original_reputations = [w.reputation for w in workers]\n",
        "    for w in workers:\n",
        "        w.reputation = 0.8  # Default value\n",
        "\n",
        "    assignments = rags_matching(workers, tasks)\n",
        "\n",
        "    # Restore reputations\n",
        "    for w, rep in zip(workers, original_reputations):\n",
        "        w.reputation = rep\n",
        "\n",
        "    return assignments\n",
        "\n",
        "def pota_centralized(workers, tasks):\n",
        "    \"\"\"POTA without federated learning - centralized RL\"\"\"\n",
        "    # Train a single global model\n",
        "    global_model = LSTMPolicy().to(device)\n",
        "    optimizer = optim.Adam(global_model.parameters(), lr=0.005)\n",
        "\n",
        "    # Train on aggregated data\n",
        "    states = torch.randn(10000, 1, 5, device=device)\n",
        "    actions = torch.randint(0, 3, (10000,), device=device)\n",
        "    rewards = torch.rand(10000, device=device)\n",
        "\n",
        "    for epoch in range(20):\n",
        "        outputs = global_model(states)\n",
        "        loss = -torch.log(outputs[torch.arange(len(actions)), actions]) * rewards\n",
        "        loss = loss.mean()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Apply global weights\n",
        "    with torch.no_grad():\n",
        "        for worker in workers:\n",
        "            state = torch.randn(1, 1, 5, device=device)\n",
        "            new_weights = global_model(state).cpu().numpy()[0]\n",
        "            worker.weights = new_weights\n",
        "\n",
        "    return rags_matching(workers, tasks)\n",
        "\n",
        "########################\n",
        "### 7. Main Simulation #\n",
        "########################\n",
        "def run_full_simulation():\n",
        "    print(f\"üöÄ Starting large-scale simulation with {N_WORKERS} workers and {N_TASKS} tasks\")\n",
        "    results = []\n",
        "    methods = {\n",
        "        \"POTA (Proposed)\": rags_matching,\n",
        "        \"Classic GS\": classic_gs,\n",
        "        \"Random Allocation\": random_matching,\n",
        "        \"FML\": fml_matching,\n",
        "        \"SenseChain+\": sensechain_matching,\n",
        "        \"POTA w/o RL\": pota_no_rl,\n",
        "        \"POTA w/o DQRS\": pota_no_dqrs,\n",
        "        \"POTA Centralized\": pota_centralized\n",
        "    }\n",
        "\n",
        "    # Generate workers and tasks\n",
        "    print(\"Generating workers and tasks...\")\n",
        "    workers = [Worker(i) for i in tqdm(range(N_WORKERS))]\n",
        "    tasks = [Task(j) for j in tqdm(range(N_TASKS))]\n",
        "\n",
        "    # Train DQRS model\n",
        "    print(\"Training DQRS VAE...\")\n",
        "    vae_model = QualityVAE().to(device)\n",
        "    optimizer = optim.Adam(vae_model.parameters(), lr=0.001)\n",
        "\n",
        "    # Generate synthetic quality features\n",
        "    features = torch.randn(100000, 3, device=device)\n",
        "    for epoch in tqdm(range(50)):\n",
        "        recon, mu, logvar = vae_model(features)\n",
        "        loss = vae_loss(recon, features, mu, logvar)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Federated RL Training\n",
        "    print(\"Training federated RL agents...\")\n",
        "    worker_models = []\n",
        "    batch_size = min(100, len(workers))\n",
        "\n",
        "    for i in tqdm(range(0, len(workers), batch_size)):\n",
        "        batch = workers[i:i+batch_size]\n",
        "        batch_models = [train_worker_rl(w, tasks) for w in batch]\n",
        "        worker_models.extend(batch_models)\n",
        "\n",
        "        # Clear memory\n",
        "        if GPU_ACCELERATED:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Apply federated averaging\n",
        "    print(\"Applying federated averaging...\")\n",
        "    global_weights = federated_average(worker_models)\n",
        "    for i, model in enumerate(worker_models):\n",
        "        model.load_state_dict(global_weights)\n",
        "        workers[i].weights = model(torch.randn(1, 1, 5, device=device)).cpu().detach().numpy()[0]\n",
        "\n",
        "    # Run all matching algorithms\n",
        "    for method_name, matching_fn in methods.items():\n",
        "        print(f\"\\nüîç Running {method_name}...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Reset assignments\n",
        "        for w in workers:\n",
        "            w.assigned_tasks = []\n",
        "\n",
        "        # Run matching\n",
        "        worker_assignments, task_assignments = matching_fn(workers, tasks)\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        # Calculate metrics\n",
        "        satisfaction = calculate_satisfaction(workers, tasks, worker_assignments)\n",
        "        coverage = calculate_task_coverage(task_assignments)\n",
        "        quality = calculate_quality(workers, tasks, worker_assignments)\n",
        "        stability = check_stability(workers, tasks, worker_assignments, task_assignments)\n",
        "\n",
        "        # Record results\n",
        "        results.append({\n",
        "            \"Method\": method_name,\n",
        "            \"Satisfaction\": satisfaction,\n",
        "            \"Task Coverage\": coverage,\n",
        "            \"Data Quality\": quality,\n",
        "            \"Stability\": stability,\n",
        "            \"Time (s)\": elapsed\n",
        "        })\n",
        "\n",
        "        print(f\"  Satisfaction: {satisfaction:.3f} | Coverage: {coverage:.1%} | \"\n",
        "              f\"Quality: {quality:.3f} | Stability: {stability:.1%} | Time: {elapsed:.1f}s\")\n",
        "\n",
        "    # Save results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"pota_results.csv\", index=False)\n",
        "    print(\"\\n‚úÖ Results saved to pota_results.csv\")\n",
        "\n",
        "    # Visualize results\n",
        "    plot_results(results_df)\n",
        "\n",
        "    return results_df\n",
        "\n",
        "def plot_results(results_df):\n",
        "    plt.figure(figsize=(14, 10))\n",
        "\n",
        "    # Satisfaction and Quality\n",
        "    plt.subplot(2, 2, 1)\n",
        "    sns.barplot(x=\"Method\", y=\"Satisfaction\", data=results_df)\n",
        "    plt.title(\"Worker Satisfaction\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    sns.barplot(x=\"Method\", y=\"Data Quality\", data=results_df)\n",
        "    plt.title(\"Data Quality Score\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Coverage and Stability\n",
        "    plt.subplot(2, 2, 3)\n",
        "    sns.barplot(x=\"Method\", y=\"Task Coverage\", data=results_df)\n",
        "    plt.title(\"Task Coverage\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.subplot(2, 2, 4)\n",
        "    sns.barplot(x=\"Method\", y=\"Stability\", data=results_df)\n",
        "    plt.title(\"Matching Stability\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"pota_metrics.png\")\n",
        "\n",
        "    # Performance comparison\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.barplot(x=\"Method\", y=\"Time (s)\", data=results_df)\n",
        "    plt.title(\"Computation Time\")\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    efficiency = results_df[\"Satisfaction\"] * results_df[\"Data Quality\"] / results_df[\"Time (s)\"]\n",
        "    results_df[\"Efficiency\"] = efficiency\n",
        "    sns.barplot(x=\"Method\", y=\"Efficiency\", data=results_df)\n",
        "    plt.title(\"Satisfaction-Quality/Time Efficiency\")\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"pota_performance.png\")\n",
        "    print(\"\\nüìä Visualizations saved to pota_metrics.png and pota_performance.png\")\n",
        "\n",
        "# Run the full simulation\n",
        "if __name__ == \"__main__\":\n",
        "    results_df = run_full_simulation()\n",
        "\n",
        "    # Display final results\n",
        "    print(\"\\n‚≠ê Final Results ‚≠ê\")\n",
        "    print(results_df[['Method', 'Satisfaction', 'Data Quality', 'Stability', 'Time (s)']])"
      ]
    }
  ]
}